{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook works on extracting unique named entities and organizations from KDD papers and passing them lists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import subprocess\n",
    "import unicodedata\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk import Tree\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from operator import itemgetter\n",
    "import polyglot\n",
    "import string\n",
    "from emailextractor import file_to_str, get_emails # paste code to .py file from following link and save within your environment path to call it: https://gist.github.com/dideler/5219706\n",
    "\n",
    "'''\n",
    "Severl issues extended the time to complete this work\n",
    "that were not related to the coding itself.  I had two\n",
    "Anaconda distros installed on my computer.  This led\n",
    "to problems with importing modules because the paths\n",
    "for installation and retrieval were mixed.  I had to\n",
    "uninstall both anacondas, reinstall, and then recreate\n",
    "my virtual environment.  Imports and installs worked cleanly\n",
    "\n",
    "To create ipython shells in a virtual environment, use:\n",
    "http://stackoverflow.com/questions/30492623/using-both-python-2-x-and-python-3-x-in-ipython-notebook\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path        = os.path.abspath(os.getcwd())\n",
    "TESTDIR     = os.path.normpath(os.path.join(os.path.expanduser(\"~\"),\"projects\",\"LC3-Creations\", \"examples\",\"KDDsample\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I experienced unicode problems early on.  Everytime I had an error, I scoured the internet for solutions. Here's the credit.\n",
    "\n",
    "\n",
    "\n",
    "- For Typeerror codes using subprocess to convert pdf2txt output to straight unicode --> http://stackoverflow.com/questions/33283603/python-popen-communicate-str-encodeencoding-utf-8-errors-ignore-cr\n",
    "- For problems with ASCII characters --> http://stackoverflow.com/questions/175240/how-do-i-convert-a-files-format-from-unicode-to-ascii-using-python\n",
    "- For unicode characters left in unicode converted to a string  --> http://stackoverflow.com/questions/8689795/how-can-i-remove-non-ascii-characters-but-leave-periods-and-spaces-using-python\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "a = unicode(subprocess.check_output(['pdf2txt.py',str(os.path.normpath(os.path.join(TESTDIR,\"p19.pdf\")))]),errors='ignore')\n",
    "document = filter(lambda x: x in string.printable,unicodedata.normalize('NFKD', a).encode('ascii','ignore').decode('unicode_escape').encode('ascii','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timeline Generation for Knowledge-Base Entities\\n\\nTimeMachine:\\n\\nTim Althoff*, Xin Luna Dong, Kevin Murphy, Safa Alai, Van Dang, Wei Zhang\\n\\n*Computer Science Department, Stanford University, Stanford, CA 94305\\n\\nGoogle, 1600 Amphitheatre Parkway, Mountain View, CA 94043\\n\\n*althoff@cs.stanford.edu {lunadong, kpmurphy, safa, vandang, weizh}@google.com\\n\\nABSTRACT\\n\\nWe present a method called TIMEMACHINE to generate a time-\\nline of events and relations for entities in a knowledge base. For\\nexample for an actor, such a timeline should show the most impor-\\ntant professional and personal milestones and relationships such as\\nworks, awards, collaborations, and family relationships. We de-\\nvelop three orthogonal timeline quality criteria that an ideal time-\\nline should satisfy: (1) it shows events that are relevant to the en-\\ntity; (2) it shows events that are temporally diverse, so they dis-\\ntribute along the time axis, avoiding visual crowding and allowing\\nfor easy user interaction, such as zooming in and out; and (3) it\\nshows events that are content diverse, so they contain many differ-\\nent types of events (e.g., for an actor, it should show movies and\\nmarriages and awards, not just movies). We present an algorithm\\nto generate such timelines for a given time period and screen size,\\nbased on submodular optimization and web-co-occurrence statis-\\ntics with provable performance guarantees. A series of user stud-\\nies using Mechanical Turk shows that all three quality criteria are\\ncrucial to produce quality timelines and that our algorithm signi-\\ncantly outperforms various baseline and state-of-the-art methods.\\n\\nCategories and Subject Descriptors: H.2.8 [Database Manage-\\nment]: Database applicationsData mining\\nGeneral Terms: Algorithms, Experimentation.\\nKeywords: Summarization, Timeline, Knowledge Base, Submod-\\nular Optimization.\\n\\n1.\\n\\nINTRODUCTION\\n\\nAs the web and other technological advancements continue to\\nbring down barriers for creation and distribution of information,\\nrelevant inf'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(re.sub('[\\s]',\" \", document)))\n",
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeline,PERSON\n",
      "Generation,ORGANIZATION\n",
      "Tim Althoff*,PERSON\n",
      "Xin Luna Dong,PERSON\n",
      "Kevin Murphy,PERSON\n",
      "Safa Alai,PERSON\n",
      "Van Dang,PERSON\n",
      "Wei Zhang,PERSON\n",
      "Stanford University,ORGANIZATION\n",
      "Stanford,PERSON\n",
      "Mountain View,PERSON\n",
      "TIMEMACHINE,ORGANIZATION\n",
      "Mechanical Turk,ORGANIZATION\n",
      "Subject,ORGANIZATION\n",
      "Knowledge Base,PERSON\n",
      "Copyright,PERSON\n",
      "NSW,ORGANIZATION\n",
      "Robert Downey Jr,PERSON\n",
      "Robert Downey,PERSON\n",
      "Iron,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Deborah Falconer,PERSON\n",
      "Susan Downey,PERSON\n",
      "Chaplin,PERSON\n",
      "Ally McBeal,PERSON\n",
      "Freebase,PERSON\n",
      "YAGO,ORGANIZATION\n",
      "KBs,ORGANIZATION\n",
      "YAGO,ORGANIZATION\n",
      "MACHINE,ORGANIZATION\n",
      "Display,PERSON\n",
      "BenStiller Deborah Falconer,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Chaplin Paramount Pictures,PERSON\n",
      "AllyMcBeal Gothika,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Robert Downey,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Tropic Thunder,PERSON\n",
      "Sherlock Holmes,ORGANIZATION\n",
      "Susan Downey,PERSON\n",
      "Further,PERSON\n",
      "CANDIDATE,ORGANIZATION\n",
      "Figure,ORGANIZATION\n",
      "Ofine,PERSON\n",
      "Online,PERSON\n",
      "Extract,PERSON\n",
      "Filter,PERSON\n",
      "Knowledge Base Web,PERSON\n",
      "TIMEMACHINE,ORGANIZATION\n",
      "KB,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "TIMEMACHINE,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "Samuel L Jackson,PERSON\n",
      "Subject Related Entity Timestamp,PERSON\n",
      "KB,ORGANIZATION\n",
      "Robert Downey Jr,PERSON\n",
      "Ns,ORGANIZATION\n",
      "Tropic Thunder,PERSON\n",
      "BenAffleck,ORGANIZATION\n",
      "SherlockHolmesin,ORGANIZATION\n",
      "Zodiac IronMan Sherlock Holmes IronMan2,PERSON\n",
      "DueDate Sherlock,ORGANIZATION\n",
      "Shadows Steve,PERSON\n",
      "Robert Downey Jr.,PERSON\n",
      "Sherlock Holmes,ORGANIZATION\n",
      "Avengers,ORGANIZATION\n",
      "Avengers,ORGANIZATION\n",
      "SUB,ORGANIZATION\n",
      "RE,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Samuel L Jackson,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Samuel L Jackson,PERSON\n",
      "USA,ORGANIZATION\n",
      "USA,ORGANIZATION\n",
      "Frequency,ORGANIZATION\n",
      "IR,ORGANIZATION\n",
      "Further,PERSON\n",
      "Existence Filter,PERSON\n",
      "Freebase,PERSON\n",
      "George Washington,PERSON\n",
      "USA,ORGANIZATION\n",
      "USA,ORGANIZATION\n",
      "Frequency Filter,ORGANIZATION\n",
      "Filter,PERSON\n",
      "Frequency,ORGANIZATION\n",
      "Freebase,PERSON\n",
      "Knowledge Vault,PERSON\n",
      "maxSX,ORGANIZATION\n",
      "Popular,PERSON\n",
      "X,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "Robert Downey Jr.,PERSON\n",
      "Avengers,ORGANIZATION\n",
      "E E,PERSON\n",
      "CONSTRAINTS,ORGANIZATION\n",
      "E2E,PERSON\n",
      "E2EPATH,ORGANIZATION\n",
      "G2E,PERSON\n",
      "Date,ORGANIZATION\n",
      "E2DPATH,ORGANIZATION\n",
      "E2D,PERSON\n",
      "E2DPATH,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "E2DPATH,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "SUB,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "CONSTRAINTS,ORGANIZATION\n",
      "Note,PERSON\n",
      "REL,ORGANIZATION\n",
      "EREL,ORGANIZATION\n",
      "DREL,ORGANIZATION\n",
      "EREL,ORGANIZATION\n",
      "DREL,ORGANIZATION\n",
      "E2EPATH,ORGANIZATION\n",
      "E2E,PERSON\n",
      "E2EPATH,ORGANIZATION\n",
      "G2E,ORGANIZATION\n",
      "E2E,PERSON\n",
      "E2EPATH,ORGANIZATION\n",
      "G2E,PERSON\n",
      "E2EPATH,ORGANIZATION\n",
      "E2ECOOC,ORGANIZATION\n",
      "E2ECOOC,ORGANIZATION\n",
      "E2ECOOC,ORGANIZATION\n",
      "SUB,ORGANIZATION\n",
      "E2EPATH,ORGANIZATION\n",
      "G2E,PERSON\n",
      "E2ECOOC,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "NLP,ORGANIZATION\n",
      "Stanford,ORGANIZATION\n",
      "Freebase IDs,PERSON\n",
      "NPMI,ORGANIZATION\n",
      "NPMI,ORGANIZATION\n",
      "PMI,ORGANIZATION\n",
      "PMI,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "E2ECOOC,ORGANIZATION\n",
      "PMI,ORGANIZATION\n",
      "Barack Obama,PERSON\n",
      "NPMI,ORGANIZATION\n",
      "PMI,ORGANIZATION\n",
      "NPMI,ORGANIZATION\n",
      "Objective,PERSON\n",
      "REL,ORGANIZATION\n",
      "E2ECOOC,ORGANIZATION\n",
      "E2DCOOC,ORGANIZATION\n",
      "Third,PERSON\n",
      "Diversity,ORGANIZATION\n",
      "T R,PERSON\n",
      "CONSTRAINTS,ORGANIZATION\n",
      "T E,PERSON\n",
      "Proof Sketch,PERSON\n",
      "Jmin,PERSON\n",
      "Jmax,PERSON\n",
      "Jmin,PERSON\n",
      "Jmin,PERSON\n",
      "Jmax,ORGANIZATION\n",
      "maxeC,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "REL T,ORGANIZATION\n",
      "GREEDYTIMELINE,ORGANIZATION\n",
      "maxSI,ORGANIZATION\n",
      "REL,ORGANIZATION\n",
      "CONSTRAINTS,ORGANIZATION\n",
      "Algorithm GREEDYTIMELINE,PERSON\n",
      "REL,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Amazon Mechanical Turk,PERSON\n",
      "CD,ORGANIZATION\n",
      "Raters,ORGANIZATION\n",
      "RPref,ORGANIZATION\n",
      "Let M,PERSON\n",
      "RAggr,ORGANIZATION\n",
      "RPref,ORGANIZATION\n",
      "NULL,ORGANIZATION\n",
      "G2E,ORGANIZATION\n",
      "FullE2D,ORGANIZATION\n",
      "FullE2E,ORGANIZATION\n",
      "FullTD,ORGANIZATION\n",
      "RPref,ORGANIZATION\n",
      "DREL,ORGANIZATION\n",
      "E2D,ORGANIZATION\n",
      "Binomial,ORGANIZATION\n",
      "Full,PERSON\n",
      "RPref,ORGANIZATION\n",
      "G2E,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Iron Man,PERSON\n",
      "G2E,ORGANIZATION\n",
      "CATE,ORGANIZATION\n",
      "CATE,ORGANIZATION\n",
      "E2E,ORGANIZATION\n",
      "CATE,ORGANIZATION\n",
      "Relevance Signals,PERSON\n",
      "EREL,ORGANIZATION\n",
      "E2E,ORGANIZATION\n",
      "E2E,ORGANIZATION\n",
      "E2D,ORGANIZATION\n",
      "E2D,PERSON\n",
      "E2D,ORGANIZATION\n",
      "Johnny Depp,PERSON\n",
      "Johnny Depps,PERSON\n",
      "Johnny Depp,PERSON\n",
      "E2E,ORGANIZATION\n",
      "E2D,ORGANIZATION\n",
      "E2E,ORGANIZATION\n",
      "Content,ORGANIZATION\n",
      "E2EPATH,ORGANIZATION\n",
      "Again,PERSON\n",
      "RELATED,ORGANIZATION\n",
      "WORK,ORGANIZATION\n",
      "Rouge,PERSON\n",
      "IR,ORGANIZATION\n",
      "Swan,PERSON\n",
      "Allan,PERSON\n",
      "Shahaf,PERSON\n",
      "Facebook,PERSON\n",
      "Timelines,PERSON\n",
      "KBs,ORGANIZATION\n",
      "Third,PERSON\n",
      "Bing,PERSON\n",
      "Timeline,PERSON\n",
      "FUTURE,ORGANIZATION\n",
      "WORK In,ORGANIZATION\n",
      "John F Kennedy,PERSON\n",
      "Bay,ORGANIZATION\n",
      "Jacqueline Kennedy Onassis,PERSON\n",
      "Cuban Missile Crisis,PERSON\n",
      "E2D,ORGANIZATION\n",
      "Again,PERSON\n",
      "Armed Forces,ORGANIZATION\n",
      "NLP,ORGANIZATION\n",
      "Robert Downey,PERSON\n",
      "Robert Downey,PERSON\n",
      "Robert Downey,PERSON\n",
      "TIMEMACHINE,ORGANIZATION\n",
      "Evgeniy Gabrilovich,PERSON\n",
      "Arun Chaganty,PERSON\n",
      "Stefanie Jegelka,PERSON\n",
      "Karthik Raman,PERSON\n",
      "Sujith Ravi,PERSON\n",
      "Ravi Kumar,PERSON\n",
      "Jeff Tamer,PERSON\n",
      "Patri Friedman,PERSON\n",
      "Danila Sinopalnikov,PERSON\n",
      "Alexander Lyashuk,PERSON\n",
      "Jure Leskovec,PERSON\n",
      "David Hallac,PERSON\n",
      "Caroline Suen,PERSON\n",
      "REFERENCES,ORGANIZATION\n",
      "Ahmed,PERSON\n",
      "Fair,PERSON\n",
      "yourHistorySemantic,ORGANIZATION\n",
      "LinkedUp,ORGANIZATION\n",
      "OKCon,ORGANIZATION\n",
      "J. Biega,PERSON\n",
      "KAIS,ORGANIZATION\n",
      "Kannan,PERSON\n",
      "J. Fiss,PERSON\n",
      "IEEE Trans Sig,ORGANIZATION\n",
      "Krause,ORGANIZATION\n",
      "Practical Approaches,PERSON\n",
      "Hard Problems,PERSON\n",
      "Cambridge University Press,PERSON\n",
      "J. VanBriesen,PERSON\n",
      "Timeline,PERSON\n",
      "WWW,ORGANIZATION\n",
      "Lin,PERSON\n",
      "Rouge,PERSON\n",
      "ACL Text Summarization Workshop,ORGANIZATION\n",
      "UAI,ORGANIZATION\n",
      "AAAI Conference,ORGANIZATION\n",
      "Articial Intelligence,ORGANIZATION\n",
      "Mazeika,PERSON\n",
      "Springer,PERSON\n",
      "Mathematical Programming,PERSON\n",
      "Timeline,PERSON\n",
      "Important Events,ORGANIZATION\n",
      "Metro,ORGANIZATION\n",
      "Dang,PERSON\n",
      "Zhang,PERSON\n",
      "SIGKDD,ORGANIZATION\n",
      "Timeline Generation,PERSON\n",
      "Modern Information Retrieval,PERSON\n",
      "ACM Press,ORGANIZATION\n",
      "J. Yang,PERSON\n",
      "J. Jacobs,PERSON\n",
      "Wang,PERSON\n",
      "J. Wang,PERSON\n",
      "Issues,PERSON\n",
      "TKDE,ORGANIZATION\n",
      "TACL,ORGANIZATION\n",
      "Freebase,PERSON\n",
      "Sprck Jones,PERSON\n",
      "Chekuri,PERSON\n",
      "SIAM Journal,ORGANIZATION\n",
      "Yago,PERSON\n",
      "WWW,ORGANIZATION\n",
      "MMR,ORGANIZATION\n",
      "Bennett,PERSON\n",
      "Springer,PERSON\n",
      "Dasgupta,PERSON\n",
      "ACL,ORGANIZATION\n",
      "Joint,PERSON\n",
      "Zhang,PERSON\n",
      "Dubinko,PERSON\n",
      "J. Magnani,PERSON\n",
      "J. Novak,PERSON\n",
      "Raghavan,PERSON\n",
      "ACM,ORGANIZATION\n",
      "JACM,ORGANIZATION\n",
      "Semantic Culturomics,ORGANIZATION\n",
      "Vision,ORGANIZATION\n",
      "Large Databases,PERSON\n",
      "VLDB,ORGANIZATION\n",
      "Automatic,PERSON\n",
      "Springer,PERSON\n",
      "CATE,ORGANIZATION\n",
      "Entity Illustration,ORGANIZATION\n",
      "WWW,ORGANIZATION\n",
      "Wang,PERSON\n",
      "Zhu,PERSON\n",
      "Williamson,PERSON\n",
      "Longitudinal Analytics,ORGANIZATION\n",
      "Zhao,PERSON\n",
      "Timeline,PERSON\n"
     ]
    }
   ],
   "source": [
    "# putting it in similar formats for visuals\n",
    "for l in entities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            print \" \".join(map(itemgetter(0), l))+\",\"+l.label()\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            print \" \".join(map(itemgetter(0), l))+\",\"+l.label()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I established two lists to hold the values that I extract from the text.  This itemgetter function will check for unique values.  First, I iterate over the extracted entities and see if the objects is a nltk.tree.Tree with a \"Person\" label.  If it is, and the length is equal to 1 (first or last name only), I append that value to the list. If it's larger, I iterate of the entity tree and pull out the first value only using itemgetter.  Then, I join the values from the list and append it to the destination list.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a list out of NLTK's standard NE chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Timeline', 'Tim Althoff*', 'Xin Luna Dong', 'Kevin Murphy', 'Safa Alai', 'Van Dang', 'Wei Zhang', 'Stanford', 'Mountain View', 'Knowledge Base', 'Copyright', 'Robert Downey Jr', 'Robert Downey', 'Iron', 'Deborah Falconer', 'Susan Downey', 'Chaplin', 'Ally McBeal', 'Freebase', 'Display', 'Chaplin Paramount Pictures', 'Tropic Thunder', 'Further', 'Ofine', 'Online', 'Extract', 'Filter', 'Knowledge Base Web', 'Samuel L Jackson', 'Subject Related Entity Timestamp', 'Zodiac IronMan Sherlock Holmes IronMan2', 'Shadows Steve', 'Robert Downey Jr.', 'Existence Filter', 'George Washington', 'Knowledge Vault', 'Popular', 'X', 'E E', 'E2E', 'G2E', 'E2D', 'Note', 'Freebase IDs', 'Barack Obama', 'Objective', 'Third', 'T R', 'T E', 'Proof Sketch', 'Jmin', 'Jmax', 'Algorithm GREEDYTIMELINE', 'Amazon Mechanical Turk', 'Let M', 'Full', 'Iron Man', 'Relevance Signals', 'Johnny Depp', 'Johnny Depps', 'Again', 'Rouge', 'Swan', 'Allan', 'Shahaf', 'Facebook', 'Timelines', 'Bing', 'John F Kennedy', 'Jacqueline Kennedy Onassis', 'Cuban Missile Crisis', 'Evgeniy Gabrilovich', 'Arun Chaganty', 'Stefanie Jegelka', 'Karthik Raman', 'Sujith Ravi', 'Ravi Kumar', 'Jeff Tamer', 'Patri Friedman', 'Danila Sinopalnikov', 'Alexander Lyashuk', 'Jure Leskovec', 'David Hallac', 'Caroline Suen', 'Ahmed', 'Fair', 'J. Biega', 'Kannan', 'J. Fiss', 'Practical Approaches', 'Hard Problems', 'Cambridge University Press', 'J. VanBriesen', 'Lin', 'Mazeika', 'Springer', 'Mathematical Programming', 'Dang', 'Zhang', 'Timeline Generation', 'Modern Information Retrieval', 'J. Yang', 'J. Jacobs', 'Wang', 'J. Wang', 'Issues', 'Sprck Jones', 'Chekuri', 'Yago', 'Bennett', 'Dasgupta', 'Joint', 'Dubinko', 'J. Magnani', 'J. Novak', 'Raghavan', 'Large Databases', 'Automatic', 'Zhu', 'Williamson', 'Zhao']\n",
      "\n",
      "\n",
      "['Generation', 'Stanford University', 'TIMEMACHINE', 'Mechanical Turk', 'Subject', 'NSW', 'Avengers', 'YAGO', 'KBs', 'MACHINE', 'BenStiller Deborah Falconer', 'AllyMcBeal Gothika', 'Sherlock Holmes', 'CANDIDATE', 'Figure', 'KB', 'Ns', 'BenAffleck', 'SherlockHolmesin', 'DueDate Sherlock', 'SUB', 'RE', 'USA', 'Frequency', 'IR', 'Frequency Filter', 'maxSX', 'CONSTRAINTS', 'E2EPATH', 'Date', 'E2DPATH', 'E2DCOOC', 'REL', 'EREL', 'DREL', 'G2E', 'E2ECOOC', 'NLP', 'Stanford', 'NPMI', 'PMI', 'Diversity', 'Jmax', 'maxeC', 'REL T', 'GREEDYTIMELINE', 'maxSI', 'CD', 'Raters', 'RPref', 'RAggr', 'NULL', 'FullE2D', 'FullE2E', 'FullTD', 'E2D', 'Binomial', 'CATE', 'E2E', 'Content', 'RELATED', 'WORK', 'FUTURE', 'WORK In', 'Bay', 'Armed Forces', 'REFERENCES', 'yourHistorySemantic', 'LinkedUp', 'OKCon', 'KAIS', 'IEEE Trans Sig', 'Krause', 'WWW', 'ACL Text Summarization Workshop', 'UAI', 'AAAI Conference', 'Articial Intelligence', 'Important Events', 'Metro', 'SIGKDD', 'ACM Press', 'TKDE', 'TACL', 'SIAM Journal', 'MMR', 'ACL', 'ACM', 'JACM', 'Semantic Culturomics', 'Vision', 'VLDB', 'Entity Illustration', 'Longitudinal Analytics']\n",
      "\n",
      "\n",
      "['Caribbean']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "persons = []\n",
    "organizations = []\n",
    "locations =[]\n",
    "\n",
    "for l in entities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if len(l)== 1:\n",
    "                if l[0][0] in persons:\n",
    "                    pass\n",
    "                else:\n",
    "                    persons.append(l[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), l)) in persons:\n",
    "                    pass\n",
    "                else:\n",
    "                    persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "                    \n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'ORGANIZATION':\n",
    "            if len(o)== 1:\n",
    "                if o[0][0] in organizations:\n",
    "                    pass\n",
    "                else:\n",
    "                    organizations.append(o[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), o)) in organizations:\n",
    "                    pass\n",
    "                else:\n",
    "                    organizations.append(\" \".join(map(itemgetter(0), o)))\n",
    "                    \n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'LOCATION':\n",
    "            if len(o)== 1:\n",
    "                if o[0][0] in locations:\n",
    "                    pass\n",
    "                else:\n",
    "                    locations.append(o[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), o)) in locations:\n",
    "                    pass\n",
    "                else:\n",
    "                    locations.append(\" \".join(map(itemgetter(0), o)))\n",
    "                    \n",
    "                \n",
    "print persons\n",
    "print\n",
    "print\n",
    "print organizations\n",
    "print\n",
    "print\n",
    "print locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford University\n",
      "Mechanical Turk\n",
      "BenStiller Deborah Falconer\n",
      "AllyMcBeal Gothika\n",
      "Sherlock Holmes\n",
      "DueDate Sherlock\n",
      "Sherlock Holmes\n",
      "Frequency Filter\n",
      "REL T\n",
      "WORK In\n",
      "Armed Forces\n",
      "IEEE Trans Sig\n",
      "ACL Text Summarization Workshop\n",
      "AAAI Conference\n",
      "Articial Intelligence\n",
      "Important Events\n",
      "Peoples Lives\n",
      "ACM Press\n",
      "New York\n",
      "SIAM Journal\n",
      "Information Retrieval\n",
      "Semantic Culturomics\n",
      "Entity Illustration\n",
      "Longitudinal Analytics\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'ORGANIZATION' or o.label() == 'GPE':\n",
    "            if len(o)>1:\n",
    "                print \" \".join(map(itemgetter(0), o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to iterate over the extracted list of entities to get a better break between person's and their university name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [nltk.word_tokenize(l) for l in persons]\n",
    "fin = [nltk.chunk.ne_chunk(nltk.pos_tag(l)) for l in tokens]\n",
    "fin;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new =[word_tokenize(l) for l in persons]\n",
    "stan = [st.tag(l) for l in new]\n",
    "stan;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating lists of named entities from Stanford's NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function looks though an extracted stanford ner list, and finds continuous entitiy labels.  This should create first name, last name records of entities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "       '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "       encoding='utf-8')\n",
    "tokenized_text = word_tokenize(re.sub('[\\s]',\" \", document))\n",
    "stanentities = st.tag(tokenized_text)\n",
    "\n",
    "\n",
    "def get_continuous_chunks(tagged_sent):\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for token, tag in tagged_sent:\n",
    "        if tag != \"O\":\n",
    "            current_chunk.append((token, tag))\n",
    "        else:\n",
    "            if current_chunk: # if the current chunk is not empty\n",
    "                continuous_chunk.append(current_chunk)\n",
    "                current_chunk = []\n",
    "    # Flush the final current_chunk into the continuous_chunk, if any.\n",
    "    if current_chunk:\n",
    "        continuous_chunk.append(current_chunk)\n",
    "    return continuous_chunk\n",
    "\n",
    "ne_tagged_sent = [('Rami', 'PERSON'), ('Eid', 'PERSON'), ('is', 'O'), ('studying', 'O'), ('at', 'O'), ('Stony', 'ORGANIZATION'), ('Brook', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('in', 'O'), ('NY', 'LOCATION')]\n",
    "\n",
    "named_entities = get_continuous_chunks(stanentities)\n",
    "named_entities_str = [\" \".join([token for token, tag in ne]) for ne in named_entities]\n",
    "named_entities_str_tag = [(\" \".join([token for token, tag in ne]), ne[0][1]) for ne in named_entities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Tim Althoff*', u'PERSON'),\n",
       " (u'Xin Luna Dong', u'PERSON'),\n",
       " (u'Kevin Murphy', u'PERSON'),\n",
       " (u'Safa Alai', u'PERSON'),\n",
       " (u'Van Dang', u'LOCATION'),\n",
       " (u'Wei Zhang *Computer Science Department', u'ORGANIZATION'),\n",
       " (u'Stanford University', u'ORGANIZATION'),\n",
       " (u'Stanford', u'ORGANIZATION'),\n",
       " (u'Google', u'ORGANIZATION'),\n",
       " (u'August 10-13', u'DATE'),\n",
       " (u'2015', u'DATE'),\n",
       " (u'Sydney', u'LOCATION'),\n",
       " (u'NSW', u'ORGANIZATION'),\n",
       " (u'Australia', u'LOCATION'),\n",
       " (u'Robert Downey', u'PERSON'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'Robert Downey Sr.', u'PERSON'),\n",
       " (u'Deborah Falconer', u'PERSON'),\n",
       " (u'Susan Downey )', u'PERSON'),\n",
       " (u'Chaplin', u'PERSON'),\n",
       " (u'YAGO', u'ORGANIZATION'),\n",
       " (u'Wikipedia', u'LOCATION'),\n",
       " (u'1965', u'DATE'),\n",
       " (u'Deborah Falconer', u'PERSON'),\n",
       " (u'Robert Downey', u'PERSON'),\n",
       " (u'Chaplin Paramount Pictures AllyMcBeal Gothika IronMan TheAvengers 1985 1990 1995 2000 2005 2010',\n",
       "  u'ORGANIZATION'),\n",
       " (u'Robert Downey Jr.', u'ORGANIZATION'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'The Avengers', u'LOCATION'),\n",
       " (u'April 11 , 2012', u'DATE'),\n",
       " (u'Robert Downey Jr.', u'ORGANIZATION'),\n",
       " (u'2007', u'DATE'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'Sherlock Holmes', u'PERSON'),\n",
       " (u'Susan Downey', u'PERSON'),\n",
       " (u'1154', u'DATE'),\n",
       " (u'60-91 %', u'PERCENT'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'April 4 , 1965', u'DATE'),\n",
       " (u'May 4 , 2012', u'DATE'),\n",
       " (u'Samuel L Jackson', u'PERSON'),\n",
       " (u'Robert Downey Jr', u'ORGANIZATION'),\n",
       " (u'1965', u'DATE'),\n",
       " (u'Tropic Thunder BenAffleck TheAvengers IronMan3 RobertDowneyJr',\n",
       "  u'ORGANIZATION'),\n",
       " (u'2009', u'DATE'),\n",
       " (u'Sherlock Holmes IronMan2 DueDate Sherlock Holmes', u'PERSON'),\n",
       " (u'Steve McQueen', u'PERSON'),\n",
       " (u'2007 2008 2009 2010 2011 2012 2013', u'DATE'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'Sherlock Holmes', u'PERSON'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'Samuel L Jackson', u'PERSON'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'Samuel L Jackson', u'PERSON'),\n",
       " (u's1', u'ORGANIZATION'),\n",
       " (u'USA', u'ORGANIZATION'),\n",
       " (u'July 4 , 1776', u'DATE'),\n",
       " (u'USA', u'ORGANIZATION'),\n",
       " (u'Existence Filter', u'ORGANIZATION'),\n",
       " (u'100 %', u'PERCENT'),\n",
       " (u'90 %', u'PERCENT'),\n",
       " (u'George Washington', u'PERSON'),\n",
       " (u'USA', u'ORGANIZATION'),\n",
       " (u'USA', u'ORGANIZATION'),\n",
       " (u'84 %', u'PERCENT'),\n",
       " (u'16 %', u'PERCENT'),\n",
       " (u'100 %', u'PERCENT'),\n",
       " (u'Frequency Filter', u'ORGANIZATION'),\n",
       " (u'87 %', u'PERCENT'),\n",
       " (u'Submodular Function Maximization Suppose', u'ORGANIZATION'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'The Avengers', u'ORGANIZATION'),\n",
       " (u'REL', u'ORGANIZATION'),\n",
       " (u'EREL', u'ORGANIZATION'),\n",
       " (u'EREL', u'ORGANIZATION'),\n",
       " (u'NLP', u'ORGANIZATION'),\n",
       " (u'Barack Obama', u'PERSON'),\n",
       " (u'REL', u'ORGANIZATION'),\n",
       " (u'Robert Downey', u'PERSON'),\n",
       " (u'90 %', u'PERCENT'),\n",
       " (u'90 %', u'PERCENT'),\n",
       " (u'Amazon', u'LOCATION'),\n",
       " (u'1154', u'DATE'),\n",
       " (u'1 1 1 1 0 1 1 1 1 1 1 0', u'DATE'),\n",
       " (u'1250', u'DATE'),\n",
       " (u'77.0 % 83.8 %', u'PERCENT'),\n",
       " (u'75.7 % 59.8 %', u'PERCENT'),\n",
       " (u'73.2 % 64.3 %', u'PERCENT'),\n",
       " (u'75.3 % 86.7 %', u'PERCENT'),\n",
       " (u'81.0 % 91.1 %', u'PERCENT'),\n",
       " (u'50 %', u'PERCENT'),\n",
       " (u'79 %', u'PERCENT'),\n",
       " (u'50 %', u'PERCENT'),\n",
       " (u'DREL', u'ORGANIZATION'),\n",
       " (u'60 %', u'PERCENT'),\n",
       " (u'95 %', u'PERCENT'),\n",
       " (u'Robert Downey Jr.', u'PERSON'),\n",
       " (u'84 %', u'PERCENT'),\n",
       " (u'Wikipedia', u'LOCATION'),\n",
       " (u'EREL', u'ORGANIZATION'),\n",
       " (u'64 %', u'PERCENT'),\n",
       " (u'Caribbean', u'LOCATION'),\n",
       " (u'2003', u'DATE'),\n",
       " (u'Johnny Depp', u'PERSON'),\n",
       " (u'Johnny Depps', u'ORGANIZATION'),\n",
       " (u'Johnny Depp', u'PERSON'),\n",
       " (u'86 %', u'PERCENT'),\n",
       " (u'91 %', u'PERCENT'),\n",
       " (u'Swan', u'ORGANIZATION'),\n",
       " (u'Allan [', u'PERSON'),\n",
       " (u'[ 26', u'DATE'),\n",
       " (u'Bing [', u'PERSON'),\n",
       " (u'90 %', u'PERCENT'),\n",
       " (u'US', u'LOCATION'),\n",
       " (u'John F Kennedy', u'PERSON'),\n",
       " (u'Jacqueline Kennedy Onassis', u'PERSON'),\n",
       " (u'Vietnam', u'LOCATION'),\n",
       " (u'US', u'LOCATION'),\n",
       " (u'US', u'LOCATION'),\n",
       " (u'NLP', u'ORGANIZATION'),\n",
       " (u'Robert Downey', u'PERSON'),\n",
       " (u'Robert Downey', u'PERSON'),\n",
       " (u'Robert Downey Sr.', u'PERSON'),\n",
       " (u'1920s', u'DATE'),\n",
       " (u'U.S.', u'LOCATION'),\n",
       " (u'Evgeniy Gabrilovich', u'PERSON'),\n",
       " (u'Arun Chaganty', u'PERSON'),\n",
       " (u'Stefanie Jegelka', u'PERSON'),\n",
       " (u'Karthik Raman', u'PERSON'),\n",
       " (u'Sujith Ravi', u'PERSON'),\n",
       " (u'Ravi Kumar', u'PERSON'),\n",
       " (u'Jeff Tamer', u'PERSON'),\n",
       " (u'Patri Friedman', u'PERSON'),\n",
       " (u'Danila Sinopalnikov', u'PERSON'),\n",
       " (u'Alexander Lyashuk', u'PERSON'),\n",
       " (u'Jure Leskovec', u'PERSON'),\n",
       " (u'David Hallac', u'PERSON'),\n",
       " (u'Caroline Suen', u'PERSON'),\n",
       " (u'] A. Ahmed', u'PERSON'),\n",
       " (u'C. H. Teo', u'PERSON'),\n",
       " (u'S. Vishwanathan', u'PERSON'),\n",
       " (u'A. Smola', u'PERSON'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'] J. Allan', u'PERSON'),\n",
       " (u'R. Gupta', u'PERSON'),\n",
       " (u'V. Khandelwal', u'PERSON'),\n",
       " (u'2001', u'DATE'),\n",
       " (u'] D. Graus', u'PERSON'),\n",
       " (u'M.-H. Peetz', u'LOCATION'),\n",
       " (u'D. Odijk', u'PERSON'),\n",
       " (u'O. de Rooij', u'PERSON'),\n",
       " (u'M. de Rijke', u'ORGANIZATION'),\n",
       " (u'2013', u'DATE'),\n",
       " (u'] T. Huet', u'PERSON'),\n",
       " (u'J. Biega', u'PERSON'),\n",
       " (u'F. M. Suchanek', u'PERSON'),\n",
       " (u'2013', u'DATE'),\n",
       " (u'H. Ji', u'PERSON'),\n",
       " (u'T. Cassidy', u'PERSON'),\n",
       " (u'S. Tamang', u'PERSON'),\n",
       " (u'2013', u'DATE'),\n",
       " (u'A. Kannan', u'PERSON'),\n",
       " (u'S. Baker', u'PERSON'),\n",
       " (u'K. Ramnath', u'PERSON'),\n",
       " (u'J. Fiss', u'PERSON'),\n",
       " (u'D. Lin', u'PERSON'),\n",
       " (u'L. Vanderwende', u'PERSON'),\n",
       " (u'R. Ansary', u'PERSON'),\n",
       " (u'A. Kapoor', u'PERSON'),\n",
       " (u'M. Uyttendaele', u'PERSON'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'S. M. Katz', u'PERSON'),\n",
       " (u'IEEE Trans Sig', u'ORGANIZATION'),\n",
       " (u'1987', u'DATE'),\n",
       " (u'A. Krause', u'PERSON'),\n",
       " (u'D. Golovin', u'PERSON'),\n",
       " (u'Cambridge University Press', u'ORGANIZATION'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'J. Leskovec', u'PERSON'),\n",
       " (u'A. Krause', u'PERSON'),\n",
       " (u'C. Guestrin', u'PERSON'),\n",
       " (u'C. Faloutsos', u'PERSON'),\n",
       " (u'J. VanBriesen', u'PERSON'),\n",
       " (u'N. Glance', u'ORGANIZATION'),\n",
       " (u'2007', u'DATE'),\n",
       " (u'J. Li', u'PERSON'),\n",
       " (u'C. Cardie', u'ORGANIZATION'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'2004', u'DATE'),\n",
       " (u'] H. Lin', u'PERSON'),\n",
       " (u'A. Bilmes', u'PERSON'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'] X. Ling', u'PERSON'),\n",
       " (u'D. S. Weld', u'PERSON'),\n",
       " (u'AAAI Conference on Articial Intelligence', u'ORGANIZATION'),\n",
       " (u'2010', u'DATE'),\n",
       " (u'A. Mazeika', u'PERSON'),\n",
       " (u'T. Tylenda', u'PERSON'),\n",
       " (u'G. Weikum', u'PERSON'),\n",
       " (u'2011', u'DATE'),\n",
       " (u'] M. Minoux', u'ORGANIZATION'),\n",
       " (u'1978', u'DATE'),\n",
       " (u'] G. L. Nemhauser', u'PERSON'),\n",
       " (u'L. A. Wolsey', u'PERSON'),\n",
       " (u'M. L. Fisher', u'PERSON'),\n",
       " (u'1978', u'DATE'),\n",
       " (u'] R. Qian', u'PERSON'),\n",
       " (u'February 2014', u'DATE'),\n",
       " (u'Feb 18 , 2015', u'DATE'),\n",
       " (u'D. Shahaf', u'PERSON'),\n",
       " (u'C. Guestrin', u'PERSON'),\n",
       " (u'E. Horvitz', u'PERSON'),\n",
       " (u'] T. Althoff', u'PERSON'),\n",
       " (u'X. L. Dong', u'PERSON'),\n",
       " (u'K. Murphy', u'PERSON'),\n",
       " (u'S. Alai', u'PERSON'),\n",
       " (u'V. Dang', u'PERSON'),\n",
       " (u'W. Zhang', u'PERSON'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'Knowledge-Base Entities', u'ORGANIZATION'),\n",
       " (u'2015', u'DATE'),\n",
       " (u'R. A. Baeza-Yates', u'PERSON'),\n",
       " (u'New York', u'LOCATION'),\n",
       " (u'1999', u'DATE'),\n",
       " (u'D. Shahaf', u'PERSON'),\n",
       " (u'J. Yang', u'PERSON'),\n",
       " (u'C. Suen', u'PERSON'),\n",
       " (u'J. Jacobs', u'PERSON'),\n",
       " (u'H. Wang', u'PERSON'),\n",
       " (u'J. Leskovec', u'PERSON'),\n",
       " (u'2013', u'DATE'),\n",
       " (u'] W. Shen', u'PERSON'),\n",
       " (u'J. Wang', u'PERSON'),\n",
       " (u'J. Han', u'PERSON'),\n",
       " (u'] D. Bamman', u'PERSON'),\n",
       " (u'N. Smith', u'PERSON'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'] K. Bollacker', u'PERSON'),\n",
       " (u'C. Evans', u'PERSON'),\n",
       " (u'P. Paritosh', u'PERSON'),\n",
       " (u'T. Sturge', u'PERSON'),\n",
       " (u'J. Taylor', u'PERSON'),\n",
       " (u'2008', u'DATE'),\n",
       " (u'R. Sipos', u'PERSON'),\n",
       " (u'A. Swaminathan', u'PERSON'),\n",
       " (u'P. Shivaswamy', u'PERSON'),\n",
       " (u'T. Joachims', u'PERSON'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'K. Sprck Jones', u'PERSON'),\n",
       " (u'] G. Calinescu', u'PERSON'),\n",
       " (u'C. Chekuri', u'PERSON'),\n",
       " (u'J. Vondrk', u'PERSON'),\n",
       " (u'Information Processing & Management', u'ORGANIZATION'),\n",
       " (u'2011', u'DATE'),\n",
       " (u'F. M. Suchanek', u'PERSON'),\n",
       " (u'G. Kasneci', u'PERSON'),\n",
       " (u'G. Weikum', u'PERSON'),\n",
       " (u'2007', u'DATE'),\n",
       " (u'] J. Carbonell', u'PERSON'),\n",
       " (u'J. Goldstein', u'PERSON'),\n",
       " (u'MMR', u'ORGANIZATION'),\n",
       " (u'1998', u'DATE'),\n",
       " (u'B. Carterette', u'PERSON'),\n",
       " (u'P. N. Bennett', u'PERSON'),\n",
       " (u'D. M. Chickering', u'PERSON'),\n",
       " (u'S. T. Dumais', u'PERSON'),\n",
       " (u'Information Retrieval', u'ORGANIZATION'),\n",
       " (u'2008', u'DATE'),\n",
       " (u'] A. Dasgupta', u'PERSON'),\n",
       " (u'R. Kumar', u'PERSON'),\n",
       " (u'S. Ravi', u'PERSON'),\n",
       " (u'2013', u'DATE'),\n",
       " (u'W. Lu', u'PERSON'),\n",
       " (u'D. Roth', u'PERSON'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'] X. Dong', u'PERSON'),\n",
       " (u'E. Gabrilovich', u'PERSON'),\n",
       " (u'G. Heitz', u'PERSON'),\n",
       " (u'W. Horn', u'PERSON'),\n",
       " (u'N. Lao', u'PERSON'),\n",
       " (u'K. Murphy', u'PERSON'),\n",
       " (u'T. Strohmann', u'PERSON'),\n",
       " (u'W. Zhang', u'PERSON'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'] M. Dubinko', u'PERSON'),\n",
       " (u'R. Kumar', u'PERSON'),\n",
       " (u'J. Magnani', u'PERSON'),\n",
       " (u'J. Novak', u'PERSON'),\n",
       " (u'P. Raghavan', u'PERSON'),\n",
       " (u'A. Tomkins', u'ORGANIZATION'),\n",
       " (u'2007', u'DATE'),\n",
       " (u'U. Feige', u'PERSON'),\n",
       " (u'1998', u'DATE'),\n",
       " (u'F. M. Suchanek', u'PERSON'),\n",
       " (u'N. Preda', u'PERSON'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'] R. Swan', u'PERSON'),\n",
       " (u'J. Allan', u'PERSON'),\n",
       " (u'2000', u'DATE'),\n",
       " (u'] T. Tran', u'PERSON'),\n",
       " (u'A. Ceroni', u'PERSON'),\n",
       " (u'M. Georgescu', u'PERSON'),\n",
       " (u'K. D. Naini', u'PERSON'),\n",
       " (u'M. Fisichella', u'PERSON'),\n",
       " (u'2014', u'DATE'),\n",
       " (u'T. A. Tuan', u'PERSON'),\n",
       " (u'S. Elbassuoni', u'PERSON'),\n",
       " (u'N. Preda', u'PERSON'),\n",
       " (u'G. Weikum', u'PERSON'),\n",
       " (u'Context-Aware Timeline for Entity Illustration', u'ORGANIZATION'),\n",
       " (u'2011', u'DATE'),\n",
       " (u'] Y. Wang', u'PERSON'),\n",
       " (u'M. Zhu', u'PERSON'),\n",
       " (u'L. Qu', u'PERSON'),\n",
       " (u'M. Spaniol', u'PERSON'),\n",
       " (u'G. Weikum', u'PERSON'),\n",
       " (u'Yago', u'PERSON'),\n",
       " (u'2010', u'DATE'),\n",
       " (u'G. Weikum', u'PERSON'),\n",
       " (u'N. Ntarmos', u'PERSON'),\n",
       " (u'M. Spaniol', u'PERSON'),\n",
       " (u'P. Triantallou', u'PERSON'),\n",
       " (u'A. Benczr', u'PERSON'),\n",
       " (u'S. Kirkpatrick', u'PERSON'),\n",
       " (u'P. Rigaux', u'PERSON'),\n",
       " (u'M. Williamson', u'PERSON'),\n",
       " (u'2011', u'DATE'),\n",
       " (u'X. W. Zhao', u'PERSON'),\n",
       " (u'Y. Guo', u'PERSON'),\n",
       " (u'R. Yan', u'PERSON'),\n",
       " (u'2013', u'DATE')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities = get_continuous_chunks(stanentities)\n",
    "named_entities_str = [\" \".join([token for token, tag in ne]) for ne in named_entities]\n",
    "named_entities_str_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Tim Althoff*',\n",
       " u'Xin Luna Dong',\n",
       " u'Kevin Murphy',\n",
       " u'Safa Alai',\n",
       " u'Robert Downey',\n",
       " u'Robert Downey Jr.',\n",
       " u'Robert Downey Sr.',\n",
       " u'Deborah Falconer',\n",
       " u'Susan Downey )',\n",
       " u'Chaplin',\n",
       " u'Sherlock Holmes',\n",
       " u'Susan Downey',\n",
       " u'Samuel L Jackson',\n",
       " u'Sherlock Holmes IronMan2 DueDate Sherlock Holmes',\n",
       " u'Steve McQueen',\n",
       " u'George Washington',\n",
       " u'Barack Obama',\n",
       " u'Johnny Depp',\n",
       " u'Allan [',\n",
       " u'Bing [',\n",
       " u'John F Kennedy',\n",
       " u'Jacqueline Kennedy Onassis',\n",
       " u'Evgeniy Gabrilovich',\n",
       " u'Arun Chaganty',\n",
       " u'Stefanie Jegelka',\n",
       " u'Karthik Raman',\n",
       " u'Sujith Ravi',\n",
       " u'Ravi Kumar',\n",
       " u'Jeff Tamer',\n",
       " u'Patri Friedman',\n",
       " u'Danila Sinopalnikov',\n",
       " u'Alexander Lyashuk',\n",
       " u'Jure Leskovec',\n",
       " u'David Hallac',\n",
       " u'Caroline Suen',\n",
       " u'A. Ahmed',\n",
       " u'C. H. Teo',\n",
       " u'S. Vishwanathan',\n",
       " u'A. Smola',\n",
       " u'J. Allan',\n",
       " u'R. Gupta',\n",
       " u'V. Khandelwal',\n",
       " u'D. Graus',\n",
       " u'D. Odijk',\n",
       " u'O. de Rooij',\n",
       " u'T. Huet',\n",
       " u'J. Biega',\n",
       " u'F. M. Suchanek',\n",
       " u'H. Ji',\n",
       " u'T. Cassidy',\n",
       " u'S. Tamang',\n",
       " u'A. Kannan',\n",
       " u'S. Baker',\n",
       " u'K. Ramnath',\n",
       " u'J. Fiss',\n",
       " u'D. Lin',\n",
       " u'L. Vanderwende',\n",
       " u'R. Ansary',\n",
       " u'A. Kapoor',\n",
       " u'M. Uyttendaele',\n",
       " u'S. M. Katz',\n",
       " u'A. Krause',\n",
       " u'D. Golovin',\n",
       " u'J. Leskovec',\n",
       " u'C. Guestrin',\n",
       " u'C. Faloutsos',\n",
       " u'J. VanBriesen',\n",
       " u'J. Li',\n",
       " u'H. Lin',\n",
       " u'A. Bilmes',\n",
       " u'X. Ling',\n",
       " u'D. S. Weld',\n",
       " u'A. Mazeika',\n",
       " u'T. Tylenda',\n",
       " u'G. Weikum',\n",
       " u'G. L. Nemhauser',\n",
       " u'L. A. Wolsey',\n",
       " u'M. L. Fisher',\n",
       " u'R. Qian',\n",
       " u'D. Shahaf',\n",
       " u'E. Horvitz',\n",
       " u'T. Althoff',\n",
       " u'X. L. Dong',\n",
       " u'K. Murphy',\n",
       " u'S. Alai',\n",
       " u'V. Dang',\n",
       " u'W. Zhang',\n",
       " u'R. A. Baeza-Yates',\n",
       " u'J. Yang',\n",
       " u'C. Suen',\n",
       " u'J. Jacobs',\n",
       " u'H. Wang',\n",
       " u'W. Shen',\n",
       " u'J. Wang',\n",
       " u'J. Han',\n",
       " u'D. Bamman',\n",
       " u'N. Smith',\n",
       " u'K. Bollacker',\n",
       " u'C. Evans',\n",
       " u'P. Paritosh',\n",
       " u'T. Sturge',\n",
       " u'J. Taylor',\n",
       " u'R. Sipos',\n",
       " u'A. Swaminathan',\n",
       " u'P. Shivaswamy',\n",
       " u'T. Joachims',\n",
       " u'K. Sprck Jones',\n",
       " u'G. Calinescu',\n",
       " u'C. Chekuri',\n",
       " u'J. Vondrk',\n",
       " u'G. Kasneci',\n",
       " u'J. Carbonell',\n",
       " u'J. Goldstein',\n",
       " u'B. Carterette',\n",
       " u'P. N. Bennett',\n",
       " u'D. M. Chickering',\n",
       " u'S. T. Dumais',\n",
       " u'A. Dasgupta',\n",
       " u'R. Kumar',\n",
       " u'S. Ravi',\n",
       " u'W. Lu',\n",
       " u'D. Roth',\n",
       " u'X. Dong',\n",
       " u'E. Gabrilovich',\n",
       " u'G. Heitz',\n",
       " u'W. Horn',\n",
       " u'N. Lao',\n",
       " u'T. Strohmann',\n",
       " u'M. Dubinko',\n",
       " u'J. Magnani',\n",
       " u'J. Novak',\n",
       " u'P. Raghavan',\n",
       " u'U. Feige',\n",
       " u'N. Preda',\n",
       " u'R. Swan',\n",
       " u'T. Tran',\n",
       " u'A. Ceroni',\n",
       " u'M. Georgescu',\n",
       " u'K. D. Naini',\n",
       " u'M. Fisichella',\n",
       " u'T. A. Tuan',\n",
       " u'S. Elbassuoni',\n",
       " u'Y. Wang',\n",
       " u'M. Zhu',\n",
       " u'L. Qu',\n",
       " u'M. Spaniol',\n",
       " u'Yago',\n",
       " u'N. Ntarmos',\n",
       " u'P. Triantallou',\n",
       " u'A. Benczr',\n",
       " u'S. Kirkpatrick',\n",
       " u'P. Rigaux',\n",
       " u'M. Williamson',\n",
       " u'X. W. Zhao',\n",
       " u'Y. Guo',\n",
       " u'R. Yan']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=[]\n",
    "for l,m in named_entities_str_tag:\n",
    "    l=re.sub('(\\])',\" \",l).strip()\n",
    "    if m == 'PERSON':\n",
    "        if l in compare:\n",
    "            pass\n",
    "        else:\n",
    "            compare.append(l)\n",
    "    else:\n",
    "        pass\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list1 = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list2 = [i for i in xrange(7,17,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7, 8, 9}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) & set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parts_of_speech(corpus):\n",
    "    \"returns named entity chunks in a given text\"\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(corpus))\n",
    "    entities = nltk.chunk.ne_chunk(tagged)\n",
    "    # Another entity extractor\n",
    "    st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "           '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "           encoding='utf-8')\n",
    "    tokenized_text = word_tokenize(corpus)\n",
    "    stanentities = st.tag(tokenized_text)\n",
    "    return entities\n",
    "def find_entities(chunks):\n",
    "    \"given list of tagged parts of speech, returns unique named entities\"\n",
    "\n",
    "    def traverse(tree):\n",
    "        \"recursively traverses an nltk.tree.Tree to find named entities\"\n",
    "        entity_names = []\n",
    "    \n",
    "        if hasattr(tree, 'node') and tree.node:\n",
    "            if tree.node == 'NE':\n",
    "                entity_names.append(' '.join([child[0] for child in tree]))\n",
    "            else:\n",
    "                for child in tree:\n",
    "                    entity_names.extend(traverse(child))\n",
    "    \n",
    "        return entity_names\n",
    "    \n",
    "    named_entities = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        entities = sorted(list(set([word for tree in chunk\n",
    "                            for word in traverse(tree)])))\n",
    "        for e in entities:\n",
    "            if e not in named_entities:\n",
    "                named_entities.append(e)\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting entities and creating lists using Polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from polyglot.text import Text\n",
    "e=Text(re.sub('[\\s]',\" \",document[:10000])).entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code iterates over the polyglot extracted entities and creates a list of person, locations, and organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import unicodedata\n",
    "\n",
    "def extraction(corpus):\n",
    "    \n",
    "    # extract entities from a single string; remove whitespace characters\n",
    "    try:\n",
    "        e = Text(re.sub('[\\s]',\" \",corpus)).entities\n",
    "    except:\n",
    "        pass #e = Text(re.sub(\"(r'(x0)',\" \",\"(re.sub('[\\s]',\" \",corpus)))).entities\n",
    "    \n",
    "    current_person =[]\n",
    "    persons =[]\n",
    "    current_org=[]\n",
    "    organizations=[]\n",
    "    current_loc=[]\n",
    "    locations=[]\n",
    "\n",
    "    for l in e:\n",
    "        if l.tag == 'I-PER':\n",
    "            for m in l:\n",
    "                current_person.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_person: # if the current chunk is not empty\n",
    "                        persons.append(\" \".join(current_person))\n",
    "                        current_person = []\n",
    "        elif l.tag == 'I-ORG':\n",
    "            for m in l:\n",
    "                current_org.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_org: # if the current chunk is not empty\n",
    "                        organizations.append(\" \".join(current_org))\n",
    "                        current_org = []\n",
    "        elif l.tag == 'I-LOC':\n",
    "            for m in l:\n",
    "                current_loc.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_loc: # if the current chunk is not empty\n",
    "                        locations.append(\" \".join(current_loc))\n",
    "                        current_loc = []\n",
    "    results = {}\n",
    "    results['persons']=persons\n",
    "    results['organizations']=organizations\n",
    "    results['locations']=locations\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tim Althoff',\n",
       " 'Xin Luna Dong',\n",
       " 'Kevin Murphy',\n",
       " 'Safa',\n",
       " 'Van Dang',\n",
       " 'Wei Zhang',\n",
       " 'KDD15',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Sr',\n",
       " 'Deborah Falconer',\n",
       " 'Susan Downey',\n",
       " 'Chaplin',\n",
       " 'Ally McBeal',\n",
       " 'BenStiller Deborah Falconer FionaApple',\n",
       " 'IronMan2 IronMan3 Robert Downey',\n",
       " 'Sr',\n",
       " 'Chaplin',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Susan Downey',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'rIn sta Samuel L Jackson',\n",
       " 'cate',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Sherlock Holmes:A',\n",
       " 'Steve McQueen',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Robert Downey Jr',\n",
       " 'Samuel L Jackson',\n",
       " 'Robert Downey Jr',\n",
       " 'Samuel L Jackson',\n",
       " 'George Washington',\n",
       " 'ure',\n",
       " 'Freebase',\n",
       " 'benet',\n",
       " 'Robert Downey Jr',\n",
       " 'REL',\n",
       " 'ned',\n",
       " 'Barack Obama',\n",
       " 'Jmin',\n",
       " 'maxT',\n",
       " 'submodular',\n",
       " 'rst',\n",
       " 'REL',\n",
       " 'REL',\n",
       " 'Robert Downey Jr.s',\n",
       " 'ducing',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'Robert Downey Jr',\n",
       " 'CATE',\n",
       " 'CATE',\n",
       " 'CATE',\n",
       " 'benet',\n",
       " 'E2D',\n",
       " 'Johnny Depp',\n",
       " 'Johnny Depps',\n",
       " 'Johnny Depp',\n",
       " 'Swan',\n",
       " 'Allan',\n",
       " 'Shahaf',\n",
       " 'Bing',\n",
       " 'John F Kennedy',\n",
       " 'Jacqueline Kennedy Onassis',\n",
       " 'raters',\n",
       " 'Robert Downey Jr.s',\n",
       " 'Robert Downey Sr',\n",
       " 'Robert Downey',\n",
       " 'Evgeniy',\n",
       " 'Arun Chaganty',\n",
       " 'Stefanie Jegelka',\n",
       " 'Karthik Raman',\n",
       " 'Sujith Ravi',\n",
       " 'Ravi Kumar',\n",
       " 'submodular',\n",
       " 'Jeff Tamer',\n",
       " 'Patri Friedman',\n",
       " 'Danila Sinopalnikov',\n",
       " 'Alexander Lyashuk',\n",
       " 'David Hallac',\n",
       " 'Caroline Suen',\n",
       " 'Ahmed',\n",
       " 'Teo',\n",
       " 'Allan',\n",
       " 'R',\n",
       " 'Gupta',\n",
       " 'Rooij',\n",
       " 'Huet',\n",
       " 'J',\n",
       " 'Biega',\n",
       " 'Ji',\n",
       " 'Cassidy',\n",
       " 'Q',\n",
       " 'Li',\n",
       " 'Kannan',\n",
       " 'Baker',\n",
       " 'Fiss',\n",
       " 'Lin',\n",
       " 'Kapoor',\n",
       " '. Katz',\n",
       " 'Krause',\n",
       " 'Leskovec',\n",
       " 'Krause',\n",
       " 'VanBriesen',\n",
       " 'Li',\n",
       " 'Lin',\n",
       " 'Lin',\n",
       " 'J',\n",
       " 'Ling',\n",
       " 'Weld',\n",
       " 'Wolsey',\n",
       " 'Fisher',\n",
       " 'Qian',\n",
       " 'Murphy',\n",
       " 'Zhang',\n",
       " 'SIGKDD',\n",
       " '.',\n",
       " 'Yates',\n",
       " 'Ribeiro',\n",
       " 'Neto',\n",
       " 'J',\n",
       " 'Yang',\n",
       " 'J',\n",
       " 'Jacobs',\n",
       " 'Wang',\n",
       " 'Shen',\n",
       " 'J',\n",
       " 'Wang',\n",
       " 'J',\n",
       " 'Smith',\n",
       " 'Evans',\n",
       " 'J',\n",
       " 'Taylor',\n",
       " 'Sprck Jones',\n",
       " 'Calinescu',\n",
       " 'Carbonell',\n",
       " 'J',\n",
       " 'Goldstein',\n",
       " 'Bennett',\n",
       " 'Dasgupta',\n",
       " 'Kumar',\n",
       " 'Ravi',\n",
       " 'Summarization',\n",
       " 'Lu',\n",
       " 'Roth',\n",
       " 'Murphy',\n",
       " 'Zhang',\n",
       " 'Kumar',\n",
       " 'J',\n",
       " 'Magnani',\n",
       " 'J',\n",
       " 'Novak',\n",
       " 'Raghavan',\n",
       " 'Tomkins',\n",
       " 'J',\n",
       " 'Allan',\n",
       " 'Tran',\n",
       " 'Georgescu',\n",
       " 'Fisichella',\n",
       " 'Tuan',\n",
       " 'Weikum',\n",
       " 'Wang',\n",
       " 'Zhu',\n",
       " 'Kirkpatrick',\n",
       " 'Williamson',\n",
       " 'Zhao',\n",
       " 'Guo',\n",
       " 'Yan',\n",
       " 'Li']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction(document)['persons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regexp = re.compile(\"REFERENCES(.*)$\")\n",
    "references = Text(regexp.search(re.sub('[\\s]',\" \",document)).group(1)).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regexp1 = re.compile(\"REFERENCES(.*)$\")\n",
    "references = Text(regexp.search(re.sub('[\\s]',\" \",document)).group(1)).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extraction(regexp.search(re.sub('[\\s]',\" \",document)).group(1))['persons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truth Sets to test extraction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 authors\n",
      "\n",
      "There are 3 author organizations\n",
      "\n",
      "There are 7 author locations\n",
      "\n",
      "There are 152 authors in the references\n"
     ]
    }
   ],
   "source": [
    "#p19.pdf\n",
    "\n",
    "p19pdf_authors=['Tim Althoff*','Xin Luna Dong','Kevin Murphy','Safa Alai','Van Dang','Wei Zhang']\n",
    "p19pdf_author_organizations=['Computer Science Department','Stanford University','Google']\n",
    "p19pdf_author_locations=['Stanford, CA','Stanford','CA','Google','1600 Amphitheatre Parkway, Mountain View, CA 94043','1600 Amphitheatre Parkway','Mountain View']\n",
    "\n",
    "p19pdf_references_authors =['A. Ahmed', 'C. H. Teo', 'S. Vishwanathan','A. Smola','J. Allan', 'R. Gupta', 'V. Khandelwal',\n",
    "                           'D. Graus', 'M.-H. Peetz', 'D. Odijk', 'O. de Rooij', 'M. de Rijke','T. Huet', 'J. Biega', \n",
    "                            'F. M. Suchanek','H. Ji', 'T. Cassidy', 'Q. Li','S. Tamang', 'A. Kannan', 'S. Baker', 'K. Ramnath', \n",
    "                            'J. Fiss', 'D. Lin', 'L. Vanderwende',  'R. Ansary', 'A. Kapoor', 'Q. Ke', 'M. Uyttendaele',\n",
    "                           'S. M. Katz','A. Krause','D. Golovin','J. Leskovec', 'A. Krause', 'C. Guestrin', 'C. Faloutsos', \n",
    "                            'J. VanBriesen','N. Glance','J. Li','C. Cardie','J. Li','C. Cardie','C.-Y. Lin','H. Lin','J. A. Bilmes'\n",
    "                           'X. Ling','D. S. Weld', 'A. Mazeika', 'T. Tylenda','G. Weikum','M. Minoux', 'G. L. Nemhauser', 'L. A. Wolsey',\n",
    "                            'M. L. Fisher','R. Qian','D. Shahaf', 'C. Guestrin','E. Horvitz','T. Althoff', 'X. L. Dong', 'K. Murphy', 'S. Alai',\n",
    "                            'V. Dang','W. Zhang','R. A. Baeza-Yates', 'B. Ribeiro-Neto', 'D. Shahaf', 'J. Yang', 'C. Suen', 'J. Jacobs', 'H. Wang', 'J. Leskovec',\n",
    "                           'W. Shen', 'J. Wang', 'J. Han','D. Bamman', 'N. Smith','K. Bollacker', 'C. Evans', 'P. Paritosh', 'T. Sturge', 'J. Taylor',\n",
    "                           'R. Sipos', 'A. Swaminathan', 'P. Shivaswamy', 'T. Joachims','K. Sprck Jones','G. Calinescu', 'C. Chekuri', 'M. Pl','J. Vondrk',\n",
    "                           'F. M. Suchanek', 'G. Kasneci','G. Weikum', 'J. Carbonell' ,'J. Goldstein','B. Carterette', 'P. N. Bennett', 'D. M. Chickering',\n",
    "                            'S. T. Dumais','A. Dasgupta', 'R. Kumar','S. Ravi','Q. X. Do', 'W. Lu', 'D. Roth','X. Dong', 'E. Gabrilovich', 'G. Heitz', 'W. Horn', \n",
    "                            'N. Lao', 'K. Murphy',  'T. Strohmann', 'S. Sun','W. Zhang', 'M. Dubinko', 'R. Kumar', 'J. Magnani', 'J. Novak', 'P. Raghavan','A. Tomkins',\n",
    "                           'U. Feige','F. M. Suchanek','N. Preda','R. Swan','J. Allan', 'T. Tran', 'A. Ceroni', 'M. Georgescu', 'K. D. Naini', 'M. Fisichella',\n",
    "                           'T. A. Tuan', 'S. Elbassuoni', 'N. Preda','G. Weikum','Y. Wang', 'M. Zhu', 'L. Qu', 'M. Spaniol', 'G. Weikum',\n",
    "                           'G. Weikum', 'N. Ntarmos', 'M. Spaniol', 'P. Triantallou', 'A. A. Benczr',  'S. Kirkpatrick', 'P. Rigaux','M. Williamson',\n",
    "                           'X. W. Zhao', 'Y. Guo', 'R. Yan', 'Y. He','X. Li']\n",
    "p19pdf_allauthors=['Tim Althoff*','Xin Luna Dong','Kevin Murphy','Safa Alai','Van Dang','Wei Zhang','A. Ahmed', 'C. H. Teo', 'S. Vishwanathan','A. Smola','J. Allan', 'R. Gupta', 'V. Khandelwal',\n",
    "                           'D. Graus', 'M.-H. Peetz', 'D. Odijk', 'O. de Rooij', 'M. de Rijke','T. Huet', 'J. Biega', \n",
    "                            'F. M. Suchanek','H. Ji', 'T. Cassidy', 'Q. Li','S. Tamang', 'A. Kannan', 'S. Baker', 'K. Ramnath', \n",
    "                            'J. Fiss', 'D. Lin', 'L. Vanderwende',  'R. Ansary', 'A. Kapoor', 'Q. Ke', 'M. Uyttendaele',\n",
    "                           'S. M. Katz','A. Krause','D. Golovin','J. Leskovec', 'A. Krause', 'C. Guestrin', 'C. Faloutsos', \n",
    "                            'J. VanBriesen','N. Glance','J. Li','C. Cardie','J. Li','C. Cardie','C.-Y. Lin','H. Lin','J. A. Bilmes'\n",
    "                           'X. Ling','D. S. Weld', 'A. Mazeika', 'T. Tylenda','G. Weikum','M. Minoux', 'G. L. Nemhauser', 'L. A. Wolsey',\n",
    "                            'M. L. Fisher','R. Qian','D. Shahaf', 'C. Guestrin','E. Horvitz','T. Althoff', 'X. L. Dong', 'K. Murphy', 'S. Alai',\n",
    "                            'V. Dang','W. Zhang','R. A. Baeza-Yates', 'B. Ribeiro-Neto', 'D. Shahaf', 'J. Yang', 'C. Suen', 'J. Jacobs', 'H. Wang', 'J. Leskovec',\n",
    "                           'W. Shen', 'J. Wang', 'J. Han','D. Bamman', 'N. Smith','K. Bollacker', 'C. Evans', 'P. Paritosh', 'T. Sturge', 'J. Taylor',\n",
    "                           'R. Sipos', 'A. Swaminathan', 'P. Shivaswamy', 'T. Joachims','K. Sprck Jones','G. Calinescu', 'C. Chekuri', 'M. Pl','J. Vondrk',\n",
    "                           'F. M. Suchanek', 'G. Kasneci','G. Weikum', 'J. Carbonell' ,'J. Goldstein','B. Carterette', 'P. N. Bennett', 'D. M. Chickering',\n",
    "                            'S. T. Dumais','A. Dasgupta', 'R. Kumar','S. Ravi','Q. X. Do', 'W. Lu', 'D. Roth','X. Dong', 'E. Gabrilovich', 'G. Heitz', 'W. Horn', \n",
    "                            'N. Lao', 'K. Murphy',  'T. Strohmann', 'S. Sun','W. Zhang', 'M. Dubinko', 'R. Kumar', 'J. Magnani', 'J. Novak', 'P. Raghavan','A. Tomkins',\n",
    "                           'U. Feige','F. M. Suchanek','N. Preda','R. Swan','J. Allan', 'T. Tran', 'A. Ceroni', 'M. Georgescu', 'K. D. Naini', 'M. Fisichella',\n",
    "                           'T. A. Tuan', 'S. Elbassuoni', 'N. Preda','G. Weikum','Y. Wang', 'M. Zhu', 'L. Qu', 'M. Spaniol', 'G. Weikum',\n",
    "                           'G. Weikum', 'N. Ntarmos', 'M. Spaniol', 'P. Triantallou', 'A. A. Benczr',  'S. Kirkpatrick', 'P. Rigaux','M. Williamson',\n",
    "                           'X. W. Zhao', 'Y. Guo', 'R. Yan', 'Y. He','X. Li']\n",
    "\n",
    "print \"There are %r authors\" % len(p19pdf_authors)\n",
    "print  # white space\n",
    "print \"There are %r author organizations\" %len(p19pdf_author_organizations)\n",
    "print \n",
    "print \"There are %r author locations\" % len(p19pdf_author_locations)\n",
    "print  \n",
    "print \"There are %r authors in the references\" %len(p19pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 authors\n",
      "\n",
      "There are 6 author organizations\n",
      "\n",
      "There are 8 author locations\n",
      "\n",
      "There are 106 authors in the references\n"
     ]
    }
   ],
   "source": [
    "#p29.pdf\n",
    "\n",
    "p29pdf_authors=['Laurent Amsaleg','Stephane Girard','Oussama Chelly','Teddy Furon','Michael E. Houle','Ken-ichi Kawarabayashi',\n",
    "               'Michael Nett']\n",
    "p29pdf_author_organizations=['Equipe LINKMEDIA','Campus Universitaire de Beaulieu','CNRS/IRISA Rennes','National Institute of Informatics',\n",
    "                             'Equipe MISTIS INRIA','Google']\n",
    "p29pdf_author_locations=['Campus Universitaire de Beaulieu','35042 Rennes Cedex, France','France','-1-2 Hitotsubashi, Chiyoda-ku Tokyo 101-8430, Japan',\n",
    "                        'Japan','6-10-1 Roppongi, Minato-ku Tokyo 106-6126','Inovallee, 655, Montbonnot 38334 Saint-Ismier Cedex','Tokyo']\n",
    "\n",
    "p29pdf_references_authors =['A. A. Balkema','L. de Haan','N. Bingham', 'C. Goldie','J. Teugels','N. Boujemaa', 'J. Fauqueur', 'M. Ferecatu', 'F. Fleuret',\n",
    "                            'V. Gouet', 'B. LeSaux','H. Sahbi','C. Bouveyron', 'G. Celeux', 'S. Girard','J. Bruske', 'G. Sommer',\n",
    "                           'F. Camastra','A. Vinciarelli','S. Coles','J. Costa' ,'A. Hero','T. de Vries', 'S. Chawla','M. E. Houle',\n",
    "                           'R. A. Fisher','L. H. C. Tippett','M. I. Fraga Alves', 'L. de Haan','T. Lin','M. I. Fraga Alves', 'M. I. Gomes','L. de Haan',\n",
    "                           'B. V. Gnedenko',' A. Gupta', 'R. Krauthgamer','J. R. Lee','A. Gupta', 'R. Krauthgamer','J. R. Lee','M. Hein','J.-Y. Audibert',\n",
    "                           'B. M. Hill','M. E. Houle','M. E. Houle','M. E. Houle','M. E. Houle', 'H. Kashima', 'M. Nett','M. E. Houle', 'X. Ma', 'M. Nett',\n",
    "                            'V. Oria','M. E. Houle', 'X. Ma', 'V. Oria','J. Sun','M. E. Houle','M. Nett','H. Jegou', 'R. Tavenard', 'M. Douze','L. Amsaleg',\n",
    "                           'I. Jollie','D. R. Karger','M. Ruhl','J. Karhunen','J. Joutsensalo','Y. LeCun', 'L. Bottou', 'Y. Bengio', 'P. Haner',\n",
    "                           'J. Pickands, III','C. R. Rao','S. T. Roweis','L. K. Saul','A. Rozza', 'G. Lombardi', 'C. Ceruti', 'E. Casiraghi', 'P. Campadelli',\n",
    "                           'B. Scholkopf', 'A. J. Smola','K.-R. Muller','U. Shaft','R. Ramakrishnan',' F. Takens','J. Tenenbaum', 'V. D. Silva','J. Langford',\n",
    "                           'J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. Venna','S. Kaski',\n",
    "                           'P. Verveer','R. Duin','J. von Brunken', 'M. E. Houle', 'A. Zimek','J. von Brunken', 'M. E. Houle','A. Zimek']\n",
    "\n",
    "p29pdf_allauthors=['Laurent Amsaleg','Stephane Girard','Oussama Chelly','Teddy Furon','Michael E. Houle','Ken-ichi Kawarabayashi',\n",
    "               'Michael Nett','A. A. Balkema','L. de Haan','N. Bingham', 'C. Goldie','J. Teugels','N. Boujemaa', 'J. Fauqueur', 'M. Ferecatu', 'F. Fleuret',\n",
    "                            'V. Gouet', 'B. LeSaux','H. Sahbi','C. Bouveyron', 'G. Celeux', 'S. Girard','J. Bruske', 'G. Sommer',\n",
    "                           'F. Camastra','A. Vinciarelli','S. Coles','J. Costa' ,'A. Hero','T. de Vries', 'S. Chawla','M. E. Houle',\n",
    "                           'R. A. Fisher','L. H. C. Tippett','M. I. Fraga Alves', 'L. de Haan','T. Lin','M. I. Fraga Alves', 'M. I. Gomes','L. de Haan',\n",
    "                           'B. V. Gnedenko',' A. Gupta', 'R. Krauthgamer','J. R. Lee','A. Gupta', 'R. Krauthgamer','J. R. Lee','M. Hein','J.-Y. Audibert',\n",
    "                           'B. M. Hill','M. E. Houle','M. E. Houle','M. E. Houle','M. E. Houle', 'H. Kashima', 'M. Nett','M. E. Houle', 'X. Ma', 'M. Nett',\n",
    "                            'V. Oria','M. E. Houle', 'X. Ma', 'V. Oria','J. Sun','M. E. Houle','M. Nett','H. Jegou', 'R. Tavenard', 'M. Douze','L. Amsaleg',\n",
    "                           'I. Jollie','D. R. Karger','M. Ruhl','J. Karhunen','J. Joutsensalo','Y. LeCun', 'L. Bottou', 'Y. Bengio', 'P. Haner',\n",
    "                           'J. Pickands, III','C. R. Rao','S. T. Roweis','L. K. Saul','A. Rozza', 'G. Lombardi', 'C. Ceruti', 'E. Casiraghi', 'P. Campadelli',\n",
    "                           'B. Scholkopf', 'A. J. Smola','K.-R. Muller','U. Shaft','R. Ramakrishnan',' F. Takens','J. Tenenbaum', 'V. D. Silva','J. Langford',\n",
    "                           'J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. Venna','S. Kaski',\n",
    "                           'P. Verveer','R. Duin','J. von Brunken', 'M. E. Houle', 'A. Zimek','J. von Brunken', 'M. E. Houle','A. Zimek']\n",
    "\n",
    "\n",
    "print \"There are %r authors\" % len(p29pdf_authors)\n",
    "print  # white space\n",
    "print \"There are %r author organizations\" %len(p29pdf_author_organizations)\n",
    "print \n",
    "print \"There are %r author locations\" % len(p29pdf_author_locations)\n",
    "print  \n",
    "print \"There are %r authors in the references\" %len(p29pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(compare) & set(p29pdf_allauthors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p29pdf_allauthors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st. Our approach is to generate a large set of events, and then to lter out irrelevant ones. We give an evaluation of this ltering step. This  Candidate Event Generation  Event Selection  (Ofine: Correctness & Coverage)  (Online: Relevance & Diversity)  Extract   timestamped   candidate   events  /m/016z2j  Filter   irrelevant  candidates  Select events   within time   span  Knowledge Base  Web Co-occurrence  time span: 19882014  Figure 2: System architecture. TIMEMACHINE traverses the KB ofine to generate candidate events for a subject of interest (e.g., Robert Downey Jr.). At run time, the user species a time period of interest and TIMEMACHINE selects a subset of events from the candidates to generate the timeline.  Robert Downey Jr.  B  o  D  s  t  a  r  I  n  April 4, 1965  1-hop  event  May 4, 2012  2-hop  event  ate relD  The Avengers  rIn sta  Samuel L Jackson  related through   2-hop event  Subject  Related Entity  Timestamp  Figure 3: An illustration of the event candidate generation step. Events are short paths that are associated with a timestamp.  is a necessary preparation step for our key contribution in this paper (described in the following section): dynamically sel'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\s]',\" \",document)[9300:10500]\n",
    "#regexp.search(re.sub('[\\s]',\" \",document)).group(1)[4900:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locations': ['CA',\n",
       "  'View ,',\n",
       "  'kpmurphy',\n",
       "  'safa',\n",
       "  'vandang',\n",
       "  'Submod',\n",
       "  'Sydney',\n",
       "  'NSW',\n",
       "  'Australia',\n",
       "  'American',\n",
       "  'YAGO',\n",
       "  '1Even',\n",
       "  'USA',\n",
       "  'Sec',\n",
       "  'H',\n",
       "  'Jmax',\n",
       "  'raters',\n",
       "  'Rouge',\n",
       "  'rize',\n",
       "  'Vietnam',\n",
       "  'U.S',\n",
       "  'Jure',\n",
       "  'OKCon',\n",
       "  'Rouge',\n",
       "  'New York'],\n",
       " 'organizations': ['Computer Science Department',\n",
       "  'Stanford University',\n",
       "  'Stanford',\n",
       "  'Knowledge',\n",
       "  'ACM',\n",
       "  'KBs',\n",
       "  'Chaplin Paramount Pictures',\n",
       "  'Tropic Thunder',\n",
       "  'USA',\n",
       "  'USA',\n",
       "  'Stanford',\n",
       "  'PMI',\n",
       "  'PMI',\n",
       "  'PMI',\n",
       "  'PMI',\n",
       "  'tw',\n",
       "  'REL',\n",
       "  'Amazon',\n",
       "  'Base',\n",
       "  'rst Pirates',\n",
       "  'Facebook',\n",
       "  'KBs',\n",
       "  'Cuban',\n",
       "  'Cuban Missile',\n",
       "  'Armed Forces',\n",
       "  'Users',\n",
       "  'IEEE Trans Sig',\n",
       "  'Cambridge University Press',\n",
       "  'AAAI Conference',\n",
       "  'Articial Intelligence',\n",
       "  'Springer',\n",
       "  'ACM Press',\n",
       "  'Processing & Management',\n",
       "  'Computing',\n",
       "  'Springer',\n",
       "  'ACM',\n",
       "  'Wikipevent',\n",
       "  'WISE',\n",
       "  'Springer'],\n",
       " 'persons': ['Tim Althoff',\n",
       "  'Xin Luna Dong',\n",
       "  'Kevin Murphy',\n",
       "  'Safa',\n",
       "  'Van Dang',\n",
       "  'Wei Zhang',\n",
       "  'KDD15',\n",
       "  'Robert Downey Jr',\n",
       "  'Robert Downey Jr',\n",
       "  'Robert Downey Sr',\n",
       "  'Deborah Falconer',\n",
       "  'Susan Downey',\n",
       "  'Chaplin',\n",
       "  'Ally McBeal',\n",
       "  'BenStiller Deborah Falconer FionaApple',\n",
       "  'IronMan2 IronMan3 Robert Downey',\n",
       "  'Sr',\n",
       "  'Chaplin',\n",
       "  'Robert Downey Jr',\n",
       "  'Robert Downey Jr',\n",
       "  'Robert Downey Jr',\n",
       "  'Sherlock Holmes',\n",
       "  'Susan Downey',\n",
       "  'Robert Downey Jr',\n",
       "  'Robert Downey Jr',\n",
       "  'rIn sta Samuel L Jackson',\n",
       "  'cate',\n",
       "  'Robert Downey Jr',\n",
       "  'Sherlock Holmes',\n",
       "  'Sherlock Holmes:A',\n",
       "  'Steve McQueen',\n",
       "  'Robert Downey Jr',\n",
       "  'Sherlock Holmes',\n",
       "  'Robert Downey Jr',\n",
       "  'Samuel L Jackson',\n",
       "  'Robert Downey Jr',\n",
       "  'Samuel L Jackson',\n",
       "  'George Washington',\n",
       "  'ure',\n",
       "  'Freebase',\n",
       "  'benet',\n",
       "  'Robert Downey Jr',\n",
       "  'REL',\n",
       "  'ned',\n",
       "  'Barack Obama',\n",
       "  'Jmin',\n",
       "  'maxT',\n",
       "  'submodular',\n",
       "  'rst',\n",
       "  'REL',\n",
       "  'REL',\n",
       "  'Robert Downey Jr.s',\n",
       "  'ducing',\n",
       "  'raters',\n",
       "  'raters',\n",
       "  'raters',\n",
       "  'raters',\n",
       "  'raters',\n",
       "  'Robert Downey Jr',\n",
       "  'CATE',\n",
       "  'CATE',\n",
       "  'CATE',\n",
       "  'benet',\n",
       "  'E2D',\n",
       "  'Johnny Depp',\n",
       "  'Johnny Depps',\n",
       "  'Johnny Depp',\n",
       "  'Swan',\n",
       "  'Allan',\n",
       "  'Shahaf',\n",
       "  'Bing',\n",
       "  'John F Kennedy',\n",
       "  'Jacqueline Kennedy Onassis',\n",
       "  'raters',\n",
       "  'Robert Downey Jr.s',\n",
       "  'Robert Downey Sr',\n",
       "  'Robert Downey',\n",
       "  'Evgeniy',\n",
       "  'Arun Chaganty',\n",
       "  'Stefanie Jegelka',\n",
       "  'Karthik Raman',\n",
       "  'Sujith Ravi',\n",
       "  'Ravi Kumar',\n",
       "  'submodular',\n",
       "  'Jeff Tamer',\n",
       "  'Patri Friedman',\n",
       "  'Danila Sinopalnikov',\n",
       "  'Alexander Lyashuk',\n",
       "  'David Hallac',\n",
       "  'Caroline Suen',\n",
       "  'Ahmed',\n",
       "  'Teo',\n",
       "  'Allan',\n",
       "  'R',\n",
       "  'Gupta',\n",
       "  'Rooij',\n",
       "  'Huet',\n",
       "  'J',\n",
       "  'Biega',\n",
       "  'Ji',\n",
       "  'Cassidy',\n",
       "  'Q',\n",
       "  'Li',\n",
       "  'Kannan',\n",
       "  'Baker',\n",
       "  'Fiss',\n",
       "  'Lin',\n",
       "  'Kapoor',\n",
       "  '. Katz',\n",
       "  'Krause',\n",
       "  'Leskovec',\n",
       "  'Krause',\n",
       "  'VanBriesen',\n",
       "  'Li',\n",
       "  'Lin',\n",
       "  'Lin',\n",
       "  'J',\n",
       "  'Ling',\n",
       "  'Weld',\n",
       "  'Wolsey',\n",
       "  'Fisher',\n",
       "  'Qian',\n",
       "  'Murphy',\n",
       "  'Zhang',\n",
       "  'SIGKDD',\n",
       "  '.',\n",
       "  'Yates',\n",
       "  'Ribeiro',\n",
       "  'Neto',\n",
       "  'J',\n",
       "  'Yang',\n",
       "  'J',\n",
       "  'Jacobs',\n",
       "  'Wang',\n",
       "  'Shen',\n",
       "  'J',\n",
       "  'Wang',\n",
       "  'J',\n",
       "  'Smith',\n",
       "  'Evans',\n",
       "  'J',\n",
       "  'Taylor',\n",
       "  'Sprck Jones',\n",
       "  'Calinescu',\n",
       "  'Carbonell',\n",
       "  'J',\n",
       "  'Goldstein',\n",
       "  'Bennett',\n",
       "  'Dasgupta',\n",
       "  'Kumar',\n",
       "  'Ravi',\n",
       "  'Summarization',\n",
       "  'Lu',\n",
       "  'Roth',\n",
       "  'Murphy',\n",
       "  'Zhang',\n",
       "  'Kumar',\n",
       "  'J',\n",
       "  'Magnani',\n",
       "  'J',\n",
       "  'Novak',\n",
       "  'Raghavan',\n",
       "  'Tomkins',\n",
       "  'J',\n",
       "  'Allan',\n",
       "  'Tran',\n",
       "  'Georgescu',\n",
       "  'Fisichella',\n",
       "  'Tuan',\n",
       "  'Weikum',\n",
       "  'Wang',\n",
       "  'Zhu',\n",
       "  'Kirkpatrick',\n",
       "  'Williamson',\n",
       "  'Zhao',\n",
       "  'Guo',\n",
       "  'Yan',\n",
       "  'Li']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tim Althoff',\n",
       " 'Xin Luna Dong',\n",
       " 'Kevin Murphy',\n",
       " 'Safa',\n",
       " 'Van Dang',\n",
       " 'Wei Zhang',\n",
       " 'KDD15',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Sr',\n",
       " 'Deborah Falconer',\n",
       " 'Susan Downey',\n",
       " 'Chaplin',\n",
       " 'Ally McBeal',\n",
       " 'BenStiller Deborah Falconer FionaApple',\n",
       " 'IronMan2 IronMan3 Robert Downey',\n",
       " 'Sr',\n",
       " 'Chaplin',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Susan Downey',\n",
       " 'Robert Downey Jr',\n",
       " 'Robert Downey Jr',\n",
       " 'rIn sta Samuel L Jackson',\n",
       " 'cate',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Sherlock Holmes:A',\n",
       " 'Steve McQueen',\n",
       " 'Robert Downey Jr',\n",
       " 'Sherlock Holmes',\n",
       " 'Robert Downey Jr',\n",
       " 'Samuel L Jackson',\n",
       " 'Robert Downey Jr',\n",
       " 'Samuel L Jackson',\n",
       " 'George Washington',\n",
       " 'ure',\n",
       " 'Freebase',\n",
       " 'benet',\n",
       " 'Robert Downey Jr',\n",
       " 'REL',\n",
       " 'ned',\n",
       " 'Barack Obama',\n",
       " 'Jmin',\n",
       " 'maxT',\n",
       " 'submodular',\n",
       " 'rst',\n",
       " 'REL',\n",
       " 'REL',\n",
       " 'Robert Downey Jr.s',\n",
       " 'ducing',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'raters',\n",
       " 'Robert Downey Jr',\n",
       " 'CATE',\n",
       " 'CATE',\n",
       " 'CATE',\n",
       " 'benet',\n",
       " 'E2D',\n",
       " 'Johnny Depp',\n",
       " 'Johnny Depps',\n",
       " 'Johnny Depp',\n",
       " 'Swan',\n",
       " 'Allan',\n",
       " 'Shahaf',\n",
       " 'Bing',\n",
       " 'John F Kennedy',\n",
       " 'Jacqueline Kennedy Onassis',\n",
       " 'raters',\n",
       " 'Robert Downey Jr.s',\n",
       " 'Robert Downey Sr',\n",
       " 'Robert Downey',\n",
       " 'Evgeniy',\n",
       " 'Arun Chaganty',\n",
       " 'Stefanie Jegelka',\n",
       " 'Karthik Raman',\n",
       " 'Sujith Ravi',\n",
       " 'Ravi Kumar',\n",
       " 'submodular',\n",
       " 'Jeff Tamer',\n",
       " 'Patri Friedman',\n",
       " 'Danila Sinopalnikov',\n",
       " 'Alexander Lyashuk',\n",
       " 'David Hallac',\n",
       " 'Caroline Suen',\n",
       " 'Ahmed',\n",
       " 'Teo',\n",
       " 'Allan',\n",
       " 'R',\n",
       " 'Gupta',\n",
       " 'Rooij',\n",
       " 'Huet',\n",
       " 'J',\n",
       " 'Biega',\n",
       " 'Ji',\n",
       " 'Cassidy',\n",
       " 'Q',\n",
       " 'Li',\n",
       " 'Kannan',\n",
       " 'Baker',\n",
       " 'Fiss',\n",
       " 'Lin',\n",
       " 'Kapoor',\n",
       " '. Katz',\n",
       " 'Krause',\n",
       " 'Leskovec',\n",
       " 'Krause',\n",
       " 'VanBriesen',\n",
       " 'Li',\n",
       " 'Lin',\n",
       " 'Lin',\n",
       " 'J',\n",
       " 'Ling',\n",
       " 'Weld',\n",
       " 'Wolsey',\n",
       " 'Fisher',\n",
       " 'Qian',\n",
       " 'Murphy',\n",
       " 'Zhang',\n",
       " 'SIGKDD',\n",
       " '.',\n",
       " 'Yates',\n",
       " 'Ribeiro',\n",
       " 'Neto',\n",
       " 'J',\n",
       " 'Yang',\n",
       " 'J',\n",
       " 'Jacobs',\n",
       " 'Wang',\n",
       " 'Shen',\n",
       " 'J',\n",
       " 'Wang',\n",
       " 'J',\n",
       " 'Smith',\n",
       " 'Evans',\n",
       " 'J',\n",
       " 'Taylor',\n",
       " 'Sprck Jones',\n",
       " 'Calinescu',\n",
       " 'Carbonell',\n",
       " 'J',\n",
       " 'Goldstein',\n",
       " 'Bennett',\n",
       " 'Dasgupta',\n",
       " 'Kumar',\n",
       " 'Ravi',\n",
       " 'Summarization',\n",
       " 'Lu',\n",
       " 'Roth',\n",
       " 'Murphy',\n",
       " 'Zhang',\n",
       " 'Kumar',\n",
       " 'J',\n",
       " 'Magnani',\n",
       " 'J',\n",
       " 'Novak',\n",
       " 'Raghavan',\n",
       " 'Tomkins',\n",
       " 'J',\n",
       " 'Allan',\n",
       " 'Tran',\n",
       " 'Georgescu',\n",
       " 'Fisichella',\n",
       " 'Tuan',\n",
       " 'Weikum',\n",
       " 'Wang',\n",
       " 'Zhu',\n",
       " 'Kirkpatrick',\n",
       " 'Williamson',\n",
       " 'Zhao',\n",
       " 'Guo',\n",
       " 'Yan',\n",
       " 'Li']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class entities(object):\n",
    "  def __init__(self):\n",
    "    self.persons = extraction(document)['persons']\n",
    "    self.organizations = extraction(document)['organizations']\n",
    "\n",
    "my_shape = entities()\n",
    "my_shape.persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to extract emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('*althoff@cs.stanford.edu', 'weizh}@google.com')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(get_emails(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get only the Title and Author Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timeline Generation for Knowledge-Base Entities  TimeMachine:  Tim Althoff*, Xin Luna Dong, Kevin Murphy, Safa Alai, Van Dang, Wei Zhang  *Computer Science Department, Stanford University, Stanford, CA 94305  Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043  *althoff@cs.stanford.edu {lunadong, kpmurphy, safa, vandang, weizh}@google.com  '"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=re.compile('(.*)(?=ABSTRACT)')\n",
    "abstract = p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Title Only (or most of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timeline Generation for Knowledge-Base Entities'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=re.compile('(.+)(\\\\n\\\\n)')\n",
    "q=re.compile('(?<=\\\\n\\\\n)(.+?)(?=\\\\n\\\\n)')\n",
    "#p.search(document).group(1)+\" \"+q.search(document).group(1)\n",
    "p.search(document).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Abstract only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  We present a method called TIMEMACHINE to generate a time- line of events and relations for entities in a knowledge base. For example for an actor, such a timeline should show the most impor- tant professional and personal milestones and relationships such as works, awards, collaborations, and family relationships. We de- velop three orthogonal timeline quality criteria that an ideal time- line should satisfy: (1) it shows events that are relevant to the en- tity; (2) it shows events that are temporally diverse, so they dis- tribute along the time axis, avoiding visual crowding and allowing for easy user interaction, such as zooming in and out; and (3) it shows events that are content diverse, so they contain many differ- ent types of events (e.g., for an actor, it should show movies and marriages and awards, not just movies). We present an algorithm to generate such timelines for a given time period and screen size, based on submodular optimization and web-co-occurrence statis- tics with provable performance guarantees. A series of user stud- ies using Mechanical Turk shows that all three quality criteria are crucial to produce quality timelines and that our algorithm signi- cantly outperforms various baseline and state-of-the-art methods.  '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=ABSTRACT)(.+)(?=Categories and Subject Descriptors)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get keywords only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': Summarization, Timeline, Knowledge Base, Submod- ular Optimization.  1.  '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=Keywords)(.+)(?=INTRODUCTION)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Categories and Subject Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Database Manage- ment']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=Categories and Subject Descriptors)(.+)(?=Keywords)')\n",
    "re.findall('\\[(.*?)\\]',p.search(re.sub('[\\s]',\" \",document)).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Body only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-469515cdab4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=INTRODUCTION)(.+)(?=ACKNOWLEDGMENTS)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p= re.compile('(?<=INTRODUCTION)(.+)(?=ACKNOWLEDGMENTS)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get CONCLUSION only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p= re.compile('(?<=CONCLUSION)(.+)(?=ACKNOWLEDGMENTS)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get References only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [1] A. Ahmed, C. H. Teo, S. Vishwanathan, and A. Smola. Fair and  balanced: Learning to present news stories. In WSDM, 2012.  [2] J. Allan, R. Gupta, and V. Khandelwal. Temporal summaries of new  topics. In SIGIR, 2001.  [15] D. Graus, M.-H. Peetz, D. Odijk, O. de Rooij, and M. de Rijke.  yourHistorySemantic linking for a personalized timeline of historic events. Workshop: LinkedUp Challenge at OKCon, 2013.  [16] T. Huet, J. Biega, and F. M. Suchanek. Mining history with le monde.  In AKBC, 2013.  [17] H. Ji, T. Cassidy, Q. Li, and S. Tamang. Tackling representation,  annotation and classication challenges for temporal knowledge base population. KAIS, 2013.  [18] A. Kannan, S. Baker, K. Ramnath, J. Fiss, D. Lin, L. Vanderwende,  R. Ansary, A. Kapoor, Q. Ke, M. Uyttendaele, et al. Mining text snippets for images on the web. In SIGKDD, 2014.  [19] S. M. Katz. Estimation of probabilities from sparse data for the  language model component of a speech recognizer. In IEEE Trans Sig. Process., 1987.  [20] A. Krause and D. Golovin. Submodular function maximization. In Tractability: Practical Approaches to Hard Problems (to appear). Cambridge University Press, 2014.  [21] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen, and  N. Glance. Cost-effective outbreak detection in networks. In SIGKDD, 2007.  [22] J. Li and C. Cardie. Timeline generation: tracking individuals on  twitter. In WWW, 2014.  [23] C.-Y. Lin. Rouge: A package for automatic evaluation of summaries.  In Proc. ACL Text Summarization Workshop, 2004.  [24] H. Lin and J. A. Bilmes. Learning mixtures of submodular shells  with application to document summarization. In UAI, 2012.  [25] X. Ling and D. S. Weld. Temporal information extraction. In AAAI  Conference on Articial Intelligence, 2010.  [26] A. Mazeika, T. Tylenda, and G. Weikum. Entity timelines: Visual  analytics and named entity evolution. In CIKM, 2011.  [27] M. Minoux. Accelerated greedy algorithms for maximizing  submodular set functions. In Optimization Techniques, pages 234243. Springer, 1978.  [28] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of  approximations for maximizing submodular set functions  I. Mathematical Programming, 14(1):265294, 1978.  [29] R. Qian. Timeline: Understanding Important Events in Peoples  Lives. http://blogs.bing.com/search/2014/02/21/ timeline-understanding-important-events-in- peoples-lives/, February 2014. Last retrieved on Feb 18, 2015.  [30] D. Shahaf, C. Guestrin, and E. Horvitz. Metro maps of science. In  [3] T. Althoff, X. L. Dong, K. Murphy, S. Alai, V. Dang, and W. Zhang.  SIGKDD, 2012.  TimeMachine: Timeline Generation for Knowledge-Base Entities. arXiv:1502.04662, 2015.  [4] R. A. Baeza-Yates and B. Ribeiro-Neto. Modern Information  Retrieval. ACM Press, New York, 1999.  [31] D. Shahaf, J. Yang, C. Suen, J. Jacobs, H. Wang, and J. Leskovec. Information cartography: creating zoomable, large-scale maps of information. In SIGKDD, 2013.  [32] W. Shen, J. Wang, and J. Han. Entity linking with a knowledge base:  [5] D. Bamman and N. Smith. Unsupervised discovery of biographical  Issues, techniques, and solutions. TKDE, 2015.  structure from text. TACL, 2(10):363376, 2014.  [6] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor.  Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, 2008.  [33] R. Sipos, A. Swaminathan, P. Shivaswamy, and T. Joachims.  Temporal corpus summarization using submodular word coverage. In CIKM, 2012.  [34] K. Sprck Jones. Automatic summarising: The state of the art.  [7] G. Calinescu, C. Chekuri, M. Pl, and J. Vondrk. Maximizing a  Information Processing & Management, 43(6):14491481, 2007.  monotone submodular function subject to a matroid constraint. SIAM Journal on Computing, 40(6):17401766, 2011.  [35] F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of  semantic knowledge. In WWW, 2007.  [8] J. Carbonell and J. Goldstein. The use of MMR, diversity-based  reranking for reordering documents and producing summaries. In SIGIR, 1998.  [9] B. Carterette, P. N. Bennett, D. M. Chickering, and S. T. Dumais.  Here or there: Preference Judgments for Relevance. In Advances in Information Retrieval. Springer, 2008.  [10] A. Dasgupta, R. Kumar, and S. Ravi. Summarization through  submodularity and dispersion. In ACL, 2013.  [11] Q. X. Do, W. Lu, and D. Roth. Joint inference for event timeline  construction. In EMNLP-CoNLL, 2012.  [12] X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy,  T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In SIGKDD, 2014. [13] M. Dubinko, R. Kumar, J. Magnani, J. Novak, P. Raghavan, and  A. Tomkins. Visualizing tags over time. TWEB, 1(2):7, 2007.  [14] U. Feige. A threshold of ln n for approximating set cover. Journal of  the ACM (JACM), 45(4):634652, 1998.  [36] F. M. Suchanek and N. Preda. Semantic Culturomics (Vision paper).  In Very Large Databases (VLDB), 2014.  [37] R. Swan and J. Allan. Automatic generation of overview timelines.  In SIGIR, 2000.  [38] T. Tran, A. Ceroni, M. Georgescu, K. D. Naini, and M. Fisichella.  Wikipevent: Leveraging wikipedia edit history for event detection. In WISE. Springer, 2014.  [39] T. A. Tuan, S. Elbassuoni, N. Preda, and G. Weikum. CATE:  Context-Aware Timeline for Entity Illustration. In WWW, 2011.  [40] Y. Wang, M. Zhu, L. Qu, M. Spaniol, and G. Weikum. Timely Yago:  harvesting, querying, and visualizing temporal knowledge from Wikipedia. In EDBT, 2010.  [41] G. Weikum, N. Ntarmos, M. Spaniol, P. Triantallou, A. A. Benczr,  S. Kirkpatrick, P. Rigaux, and M. Williamson. Longitudinal Analytics on Web Archive Data: Its About Time! In CIDR, 2011. [42] X. W. Zhao, Y. Guo, R. Yan, Y. He, and X. Li. Timeline generation  with social attention. In SIGIR, 2013.  28 '"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=REFERENCES)(.+)')\n",
    "references = p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to count the number of references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "create a match of all references by counting the number of integers enclosed by brackets (i.e. '[2]').  \n",
    "\n",
    "This is how references are labeled in the research papers\n",
    "'''\n",
    "\n",
    "len(re.findall('\\[(.*?)\\]',regexp.search(re.sub('[\\s]',\" \",document)).group(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googleapiclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NLTK standard chunk comparison to hand labeled entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "testtagged = nltk.pos_tag(nltk.word_tokenize(abstract))\n",
    "testentities = nltk.chunk.ne_chunk(testtagged)\n",
    "\n",
    "machinelist_persons=[]\n",
    "machinelist_orgs=[]\n",
    "\n",
    "for l in testentities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_persons:\n",
    "                machinelist_persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_orgs:\n",
    "                machinelist_orgs.append(\" \".join(map(itemgetter(0), l)))\n",
    "print len(machinelist_persons),len(p19pdf_authors)                \n",
    "set(machinelist_persons) & set(p19pdf_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Accuracy\" is 67.0.\n",
      "The \"Recall\" is 100.0.\n",
      "The \"Precision\" is 66.66666666666666.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative  Predicted Positive\n",
       "Negative Cases                   0                   3\n",
       "Positive Cases                   0                   6"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using explanations from this page to estimate precision and recall\n",
    "http://www.kdnuggets.com/faq/precision-recall.html\n",
    "'''\n",
    "inboth = float(len(set(machinelist_persons) & set(p19pdf_authors)))\n",
    "ext_len=float(len(machinelist_persons))\n",
    "true_len=float(len(p19pdf_authors))\n",
    "\n",
    "d = {'Predicted Negative': [0,0], 'Predicted Positive': [ext_len-true_len,inboth]}\n",
    "metrics = pd.DataFrame(d, index=['Negative Cases','Positive Cases'])\n",
    "print \"The \\\"Accuracy\\\" is %r.\\nThe \\\"Recall\\\" is %r.\\nThe \\\"Precision\\\" is %r.\" % ((round((inboth/ext_len)*100)),(round(inboth/true_len)*100),(inboth/(inboth+ext_len-true_len))*100)\n",
    "#,,\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'J. Biega',\n",
       " 'J. Fiss',\n",
       " 'J. Jacobs',\n",
       " 'J. Magnani',\n",
       " 'J. Novak',\n",
       " 'J. VanBriesen',\n",
       " 'J. Wang',\n",
       " 'J. Yang'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "testtagged = nltk.pos_tag(nltk.word_tokenize(references))\n",
    "testentities = nltk.chunk.ne_chunk(testtagged)\n",
    "\n",
    "machinelist_persons=[]\n",
    "machinelist_orgs=[]\n",
    "\n",
    "for l in testentities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_persons:\n",
    "                machinelist_persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_orgs:\n",
    "                machinelist_orgs.append(\" \".join(map(itemgetter(0), l)))\n",
    "print len(machinelist_persons),len(p19pdf_references_authors)                \n",
    "set(machinelist_persons) & set(p19pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A. Ahmed',\n",
       " 'C. H. Teo',\n",
       " 'S. Vishwanathan',\n",
       " 'A. Smola',\n",
       " 'J. Allan',\n",
       " 'R. Gupta',\n",
       " 'V. Khandelwal',\n",
       " 'D. Graus',\n",
       " 'M.-H. Peetz',\n",
       " 'D. Odijk',\n",
       " 'O. de Rooij',\n",
       " 'M. de Rijke',\n",
       " 'T. Huet',\n",
       " 'J. Biega',\n",
       " 'F. M. Suchanek',\n",
       " 'H. Ji',\n",
       " 'T. Cassidy',\n",
       " 'Q. Li',\n",
       " 'S. Tamang',\n",
       " 'A. Kannan',\n",
       " 'S. Baker',\n",
       " 'K. Ramnath',\n",
       " 'J. Fiss',\n",
       " 'D. Lin',\n",
       " 'L. Vanderwende',\n",
       " 'R. Ansary',\n",
       " 'A. Kapoor',\n",
       " 'Q. Ke',\n",
       " 'M. Uyttendaele',\n",
       " 'S. M. Katz',\n",
       " 'A. Krause',\n",
       " 'D. Golovin',\n",
       " 'J. Leskovec',\n",
       " 'A. Krause',\n",
       " 'C. Guestrin',\n",
       " 'C. Faloutsos',\n",
       " 'J. VanBriesen',\n",
       " 'N. Glance',\n",
       " 'J. Li',\n",
       " 'C. Cardie',\n",
       " 'J. Li',\n",
       " 'C. Cardie',\n",
       " 'C.-Y. Lin',\n",
       " 'H. Lin',\n",
       " 'J. A. BilmesX. Ling',\n",
       " 'D. S. Weld',\n",
       " 'A. Mazeika',\n",
       " 'T. Tylenda',\n",
       " 'G. Weikum',\n",
       " 'M. Minoux',\n",
       " 'G. L. Nemhauser',\n",
       " 'L. A. Wolsey',\n",
       " 'M. L. Fisher',\n",
       " 'R. Qian',\n",
       " 'D. Shahaf',\n",
       " 'C. Guestrin',\n",
       " 'E. Horvitz',\n",
       " 'T. Althoff',\n",
       " 'X. L. Dong',\n",
       " 'K. Murphy',\n",
       " 'S. Alai',\n",
       " 'V. Dang',\n",
       " 'W. Zhang',\n",
       " 'R. A. Baeza-Yates',\n",
       " 'B. Ribeiro-Neto',\n",
       " 'D. Shahaf',\n",
       " 'J. Yang',\n",
       " 'C. Suen',\n",
       " 'J. Jacobs',\n",
       " 'H. Wang',\n",
       " 'J. Leskovec',\n",
       " 'W. Shen',\n",
       " 'J. Wang',\n",
       " 'J. Han',\n",
       " 'D. Bamman',\n",
       " 'N. Smith',\n",
       " 'K. Bollacker',\n",
       " 'C. Evans',\n",
       " 'P. Paritosh',\n",
       " 'T. Sturge',\n",
       " 'J. Taylor',\n",
       " 'R. Sipos',\n",
       " 'A. Swaminathan',\n",
       " 'P. Shivaswamy',\n",
       " 'T. Joachims',\n",
       " 'K. Sprck Jones',\n",
       " 'G. Calinescu',\n",
       " 'C. Chekuri',\n",
       " 'M. Pl',\n",
       " 'J. Vondrk',\n",
       " 'F. M. Suchanek',\n",
       " 'G. Kasneci',\n",
       " 'G. Weikum',\n",
       " 'J. Carbonell',\n",
       " 'J. Goldstein',\n",
       " 'B. Carterette',\n",
       " 'P. N. Bennett',\n",
       " 'D. M. Chickering',\n",
       " 'S. T. Dumais',\n",
       " 'A. Dasgupta',\n",
       " 'R. Kumar',\n",
       " 'S. Ravi',\n",
       " 'Q. X. Do',\n",
       " 'W. Lu',\n",
       " 'D. Roth',\n",
       " 'X. Dong',\n",
       " 'E. Gabrilovich',\n",
       " 'G. Heitz',\n",
       " 'W. Horn',\n",
       " 'N. Lao',\n",
       " 'K. Murphy',\n",
       " 'T. Strohmann',\n",
       " 'S. Sun',\n",
       " 'W. Zhang',\n",
       " 'M. Dubinko',\n",
       " 'R. Kumar',\n",
       " 'J. Magnani',\n",
       " 'J. Novak',\n",
       " 'P. Raghavan',\n",
       " 'A. Tomkins',\n",
       " 'U. Feige',\n",
       " 'F. M. Suchanek',\n",
       " 'N. Preda',\n",
       " 'R. Swan',\n",
       " 'J. Allan',\n",
       " 'T. Tran',\n",
       " 'A. Ceroni',\n",
       " 'M. Georgescu',\n",
       " 'K. D. Naini',\n",
       " 'M. Fisichella',\n",
       " 'T. A. Tuan',\n",
       " 'S. Elbassuoni',\n",
       " 'N. Preda',\n",
       " 'G. Weikum',\n",
       " 'Y. Wang',\n",
       " 'M. Zhu',\n",
       " 'L. Qu',\n",
       " 'M. Spaniol',\n",
       " 'G. Weikum',\n",
       " 'G. Weikum',\n",
       " 'N. Ntarmos',\n",
       " 'M. Spaniol',\n",
       " 'P. Triantallou',\n",
       " 'A. A. Benczr',\n",
       " 'S. Kirkpatrick',\n",
       " 'P. Rigaux',\n",
       " 'M. Williamson',\n",
       " 'X. W. Zhao',\n",
       " 'Y. Guo',\n",
       " 'R. Yan',\n",
       " 'Y. He',\n",
       " 'X. Li']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machinelist_persons\n",
    "p19pdf_references_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Accuracy\" is 20.0.\n",
      "The \"Recall\" is 0.0.\n",
      "The \"Precision\" is -7.6923076923076925.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Cases</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative  Predicted Positive\n",
       "Negative Cases                   0                 112\n",
       "Positive Cases                   0                   8"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using explanations from this page to estimate precision and recall\n",
    "http://www.kdnuggets.com/faq/precision-recall.html\n",
    "'''\n",
    "inboth = float(len(set(machinelist_persons) & set(p19pdf_references_authors)))\n",
    "ext_len=float(len(machinelist_persons))\n",
    "true_len=float(len(p19pdf_references_authors))\n",
    "\n",
    "d = {'Predicted Negative': [0,0], 'Predicted Positive': [abs(ext_len-true_len),inboth]}\n",
    "metrics = pd.DataFrame(d, index=['Negative Cases','Positive Cases'])\n",
    "print \"The \\\"Accuracy\\\" is %r.\\nThe \\\"Recall\\\" is %r.\\nThe \\\"Precision\\\" is %r.\" % ((round((inboth/ext_len)*100)),(round(inboth/true_len)*100),(inboth/(inboth+ext_len-true_len))*100)\n",
    "#,,\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
